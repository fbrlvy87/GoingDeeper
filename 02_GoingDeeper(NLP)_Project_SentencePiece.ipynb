{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "developing-college",
   "metadata": {},
   "source": [
    "__네이버 영화리뷰 감정분석 문제에 SentencePiece 적용해 보기__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-state",
   "metadata": {},
   "source": [
    "아마 여러분들은 [네이버 영화리뷰 감정분석 태스크](https://github.com/e9t/nsmc/)를 한 번쯤은 다루어 보았을 것입니다. 한국어로 된 corpus를 다루어야 하므로 주로 KoNLPy에서 제공하는 형태소 분석기를 사용하여 텍스트를 전처리해서 RNN 모델을 분류기로 사용했을 것입니다.\n",
    "\n",
    "만약 이 문제에서 tokenizer를 sentencepiece로 바꾸어 다시 풀어본다면 더 성능이 좋아질까요? 비교해 보는 것도 흥미로울 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-earth",
   "metadata": {},
   "source": [
    "- 네이버 영화리뷰 감정분석 코퍼스에 sentencepiece를 적용시킨 모델 학습하기\n",
    "\n",
    "- 학습된 모델로 sp_tokenize() 메소드 구현하기\n",
    "\n",
    "- 구현된 토크나이저를 적용하여 네이버 영화리뷰 감정분석 모델을 재학습하기\n",
    "\n",
    "- KoNLPy 형태소 분석기를 사용한 모델과 성능 비교하기\n",
    "\n",
    "- (보너스) SentencePiece 모델의 model_type, vocab_size 등을 변경해 가면서 성능 개선 여부 확인하기\n",
    "\n",
    "- Word Vector는 활용할 필요가 없습니다. 활용이 가능하지도 않을 것입니다.\n",
    "\n",
    "- 머지않아 SentencePiece와 BERT 등의 pretrained 모델을 함께 활용하는 태스크를 다루게 될 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-devon",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-reynolds",
   "metadata": {},
   "source": [
    "# 데이터 준비와 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "italic-spyware",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T08:39:15.774300Z",
     "start_time": "2021-04-20T08:39:15.769300Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "qualified-isaac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T08:39:28.069214Z",
     "start_time": "2021-04-20T08:39:27.764119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 변수 지정\n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/ratings_test.txt')\n",
    "\n",
    "train_data.head()    # 상위 5개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "convinced-ireland",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T08:39:40.031857Z",
     "start_time": "2021-04-20T08:39:40.026671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000 50000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "regulation-preparation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T08:52:26.274634Z",
     "start_time": "2021-04-20T08:52:26.141606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146182 49157\n"
     ]
    }
   ],
   "source": [
    "train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "train_data = train_data.dropna(how = 'any') \n",
    "test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "test_data = test_data.dropna(how = 'any') \n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-clinic",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-determination",
   "metadata": {},
   "source": [
    "# 데이터 분석 및 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-prototype",
   "metadata": {},
   "source": [
    "## 데이터 리스트 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fresh-judgment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T02:12:44.401098Z",
     "start_time": "2021-04-20T02:12:44.356952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 195339\n",
      "Example:\n",
      ">> 아 더빙.. 진짜 짜증나네요 목소리\n",
      ">> 나름 심오한 뜻도 있는 듯. 그냥 학생이 선생과 놀아나는 영화는 절대 아님\n",
      ">> 단순하면서 은은한 매력의 영화\n",
      ">> 보는내내 그대로 들어맞는 예측 카리스마 없는 악역\n",
      ">> 뭐냐..시작하고 3분만에 나왔다. 리플릿 사진 보며 불안하더니만..\n"
     ]
    }
   ],
   "source": [
    "raw = list(train_data['document']) + list(test_data['document'])\n",
    "print(\"Data Size:\", len(raw))\n",
    "\n",
    "list(map(str, raw))\n",
    "print(\"Example:\")\n",
    "for sen in raw[0:100][::20]: print(\">>\", sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-flash",
   "metadata": {},
   "source": [
    "## 데이터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "basic-renaissance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T08:54:23.186341Z",
     "start_time": "2021-04-20T08:54:22.671367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 146\n",
      "문장의 평균 길이: 35\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "for sen in raw:\n",
    "    if type(sen) == type(1.0):\n",
    "        print(sen)\n",
    "    sen = str(sen)\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(raw))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in raw:\n",
    "    #sen = str(sen)\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-proxy",
   "metadata": {},
   "source": [
    "## 문장의 길이에 따른 데이터 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-inventory",
   "metadata": {},
   "source": [
    "### 문장 길이에 따른 데이터 추출 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "coordinated-apple",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T08:54:43.152892Z",
     "start_time": "2021-04-20T08:54:43.144743Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_sentence_with_length(raw, length):\n",
    "    count = 0\n",
    "    \n",
    "    for sen in raw:\n",
    "        if len(sen) == length:\n",
    "            print(sen)\n",
    "            count += 1\n",
    "            if count > 100: return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-float",
   "metadata": {},
   "source": [
    "### 문장 길이가 1인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "seventh-notebook",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T08:54:45.361955Z",
     "start_time": "2021-04-20T08:54:45.338428Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아\n",
      "잼\n",
      "1\n",
      "4\n",
      "굿\n",
      "짱\n",
      "휴\n",
      ".\n",
      "음\n",
      "?\n",
      "ㅎ\n",
      "ㅋ\n",
      "즐\n",
      "♥\n",
      "굳\n",
      "네\n",
      "ㅇ\n",
      "k\n",
      "ㅠ\n",
      "쒯\n",
      "♬\n",
      "토\n",
      "O\n",
      "똥\n",
      "z\n",
      "헐\n",
      "삼\n",
      "꽝\n",
      "!\n",
      "풉\n",
      "ㅅ\n",
      "왜\n",
      "ㄴ\n",
      "쉣\n",
      "봐\n",
      "뿌\n",
      "ㅜ\n",
      "♡\n",
      "ㅁ\n",
      "0\n",
      "ㅉ\n",
      "d\n",
      "흥\n",
      "乃\n",
      "찜\n",
      "귯\n",
      "린\n",
      "시\n",
      "ㅗ\n",
      "a\n",
      "c\n",
      "흠\n",
      "웅\n",
      "ㅣ\n",
      "오\n",
      "9\n",
      "쩜\n",
      "애\n",
      "헝\n",
      "쨩\n",
      "f\n",
      "움\n",
      "ㄳ\n",
      "업\n",
      "헉\n",
      "군\n",
      "b\n",
      ";\n",
      "g\n",
      "올\n",
      "걍\n",
      "허\n",
      "-\n",
      "쀍\n",
      "로\n",
      "ㄹ\n",
      "ㅂ\n",
      "갑\n",
      "즛\n",
      "킥\n",
      "함\n",
      "진\n",
      "ㅡ\n",
      "잠\n",
      "곧\n",
      "ㅍ\n",
      "h\n",
      "·\n",
      "캬\n",
      "ㅆ\n",
      ",\n",
      "풋\n",
      "ㄱ\n",
      "파\n",
      "ㄷ\n",
      "웩\n",
      "꺅\n",
      "욜\n",
      "ㅄ\n",
      "2\n",
      "핡\n"
     ]
    }
   ],
   "source": [
    "check_sentence_with_length(raw, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-processing",
   "metadata": {},
   "source": [
    "### 확인이 필요한 긴 문장 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fluid-sperm",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T08:54:57.989437Z",
     "start_time": "2021-04-20T08:54:57.982725Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier Index: 5\n",
      "Outlier Index: 6\n",
      "Outlier Index: 7\n",
      "Outlier Index: 8\n",
      "Outlier Index: 9\n",
      "Outlier Index: 10\n",
      "Outlier Index: 11\n",
      "Outlier Index: 12\n",
      "Outlier Index: 13\n",
      "Outlier Index: 14\n",
      "Outlier Index: 15\n",
      "Outlier Index: 16\n",
      "Outlier Index: 17\n",
      "Outlier Index: 18\n",
      "Outlier Index: 19\n",
      "Outlier Index: 20\n",
      "Outlier Index: 21\n",
      "Outlier Index: 22\n",
      "Outlier Index: 23\n",
      "Outlier Index: 24\n",
      "Outlier Index: 25\n",
      "Outlier Index: 26\n",
      "Outlier Index: 27\n",
      "Outlier Index: 28\n",
      "Outlier Index: 29\n",
      "Outlier Index: 30\n",
      "Outlier Index: 31\n",
      "Outlier Index: 32\n",
      "Outlier Index: 33\n",
      "Outlier Index: 34\n",
      "Outlier Index: 35\n",
      "Outlier Index: 36\n",
      "Outlier Index: 37\n",
      "Outlier Index: 38\n",
      "Outlier Index: 39\n",
      "Outlier Index: 40\n",
      "Outlier Index: 41\n",
      "Outlier Index: 42\n",
      "Outlier Index: 43\n",
      "Outlier Index: 44\n",
      "Outlier Index: 45\n",
      "Outlier Index: 46\n",
      "Outlier Index: 47\n"
     ]
    }
   ],
   "source": [
    "for idx, _sum in enumerate(sentence_length):\n",
    "    # 문장 내 단어의 개수가 1500을 초과하는 인덱스를 추출합니다.\n",
    "    if _sum > 1500:\n",
    "        print(\"Outlier Index:\", idx+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-butter",
   "metadata": {},
   "source": [
    "### 문장 길이가 140 이상인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "medium-engineering",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T08:55:07.876029Z",
     "start_time": "2021-04-20T08:55:07.860943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데너리스 타르 가르엔...나도 용의주인이 되고 싶다...누이랑,근친상간이나 하고 다닐지라도,소설 속에선 제일 멋진 놈이 자이메 라니스터였는데,드라마속에선,드래곤(용)이 제일 멋지네(웃음)감독님 토르-2 다크 월드는 말아 잡수셨을지라도,기본 선방은 했음\n",
      "아~ 진짜 조금만 더 손 좀 보면 왠만한 상업 영화 못지 않게 퀄리티 쩔게 만들어 질 수 있었는데 아쉽네요 그래도 충분히 재미있었습니다 개인적으로 조금만 더 잔인하게 더 자극적으로 노출씬도 화끈하게 했더라면 어땠을까 하는 국산영화라 많이 아낀 듯 보임\n",
      "평점조절위원회에서 나왔습니다(웃음)김혜선은 @내일이 오면@의 김순정,순정이 역할이 제일이다.팜므파탈로써,그 정도까지 잘해낼 줄은,정말 의외였어...연기20년 한사람에게 요즘 사극에서 벌어지고 있는,그녀에 대한 연기논란은 왠지 코미디의한장면 같음(웃음)\n",
      "사실여부를 떠나,알고왔던 아더와 너무 매칭이 안돼더라.원탁기사중 실제 검술 최고수는 랜슬롯으로 알고 있는데,트리스탄보다 못하고,싸우는 검술은 마치 중국검술 흉내낸거 같은게;; 그리고 란슬롯이 실제는 쌍검였나?너무 매칭이 안대 하튼 ㅋ기네비어역도 미스.\n",
      "진짜 이건 아님ㅋㅋㅋㅋㅋ액션영화좋아해서 액션영화만 다운받아서 꾸준히 본게 벌써 몇년인 사람임 근데 이건 진짴ㅋㅋㅋㅋㅋㅋ아무리 점수 잘 줘도 100점 만점에 10점?ㅡㅡ돈주고봤는데너무아깝다진짜ㅜㅜ그리고대체 왜 13구역 타이틀을 달고나왔는지 모르겠음 실망\n",
      "영화'산업'이라고 하잖는가? 이딴식으로 홍보 해놓고 속여서 팔았다는 게 소비자 입장에서는 짜증난다. 그나마 다행은 아주 싸구려를 상급품으로 속여판 게 아니라는 점. 그래서 1점. 차라리 연상호 감독 작품 처럼 홍보가 됐다면, 그 비슷하게 만이라도 하지\n",
      "화려한 색채때문에 눈이 아프지만 그 나름대로 화려연예계여자욕망에대해 표현해냈던거같다 보는내내 진짜 리리코심정가진 연옌들도 있을거같고..나를한번도보지못하고알지못하는사람들이날어떻게사랑하냐그런대사 나왔을때 소름돋더라 연예인들은 많은사랑받으면서도 참 허전할듯\n",
      "히가시노 게이고의 추리소설이 사랑 받는 이유는, 치밀한 트릭도 크겠지만 사람이 사람을 죽이는 행위에 감성적 정당성을 부여한 탁월한 설득력에 있다. 본 원작은 말 그대로 '헌신적 사랑'이 그 키워드였고, 용의자 x는 거기에 집중해 훌륭히 결을 살려냈다.\n",
      "TV상영종료후 1년뒤에 극장판이 나올정도의 초 대작.TV편의 설정오류 수정과 새로운 씬 추가가 주된 볼거리. 마마마는 어른들을 위한 애니이다.※우측의 리뷰를 보고 애들과 함께 볼려고 한 분들에게는 절대로 애들에게 보여줄 작품이 아니라고 강력히 주장한다\n",
      "써로게이트의 부작용에 대한 자신만의 생각으로 써로게이트를 통해 행복을 누리고 있는 사람들의 권리를 뺒아가는게 정당한것인가? 장애인이나 식물인가.. 혹은 외모컴플렉스가 있는 사람들은 써로게이트통해 행복한 삶을 살고 있었을텐데.. 너무나 이기적인 결말임.\n",
      "정말 미치도록 재미없다. 무슨 80년대 중국 괴기 판타지물 마냥 시대에 뒤떨어진 연출과 분장력과 스토리. 반전 또한 너무 뻔하다. 아니, 솔직히 반전인 줄도 몰랐다. 처음부터 계속 복선이 깔리는데 뭐가 반전인지? 흔하디흔한 미드 반전만도 못한 애들영화\n",
      "초등학생 시절에 접했던 스파이더맨 3부작을 히어로물 매니아가 된 지금 다시 찾았다. 리부트 후 세계관 확장에 신경쓰고 있지만, 독립된 세계관으로써도 깊은 여운과 재미를 줬던 샘레이미 감독과 토비 맥과이어의 스파이더맨 3부작은 정말 최고라 말하고 싶다.\n",
      "예회장의 매력이 걷잡을수 없다. 무간도 시리즈의 다른 작품들과 등장인물이 거의 완전히 다름에도 불구하고 다른 무간도 시리즈와 잘 조화되며, 이 작품만이 주는 매력 또한 상당하다. 한침의 먹방이 정말 압권. 예회장의 카리스마는 대부의 돈 꼴레오네를 연상\n",
      "어차피 무리인 소설 원작을 재현할 생각 말고, 차라리 영화 나름의 각색을 하는게 더 나았겠다. 이건 뭐 그냥 생뚱맞네. 캐릭터 깊이도 없고, 몰입도 안되고, 감독 혼자서만 감정잡고있고, 영상도 작위적. 아예 헛웃음만 나오더라. 트란안훙꺼 이제 안볼거다\n",
      "그저 옛 영화 입니다. 예전의 경향과 문화를 알고 싶으신 분은 보세요. 지금 봐도 괜찮은 고전명작의 공통점은 그 감독들이 현재까지도 활발히 활동한다는 것이죠. 대부 감독은 2000년대 이후로 성공적이지 못합니다. 구성과 전개가 너무 올드하고 지루하죠.\n",
      "미라소르비노 발킬머와 스케이트장에서 여러가지 표정 지어보일때 너무 이쁘고사랑스러웠네요.. 스토리전개에.조금은.투박한느낌이지만.. 처음 비가내릴때.작은 폐가 안에 들어가.같이 눈을.감고 비의 운율을 느낀다... 괜찮은 영화를알게되어 너무 좋은 하루였네요\n",
      "이 죽일놈의 사랑...에 어울리지 않는,이 무슨 거지같은...영화.차라리 공상과학영화로 각색해오든가...딱 국어책을 낭랑히 읽고있는,대배우의 시나리오리딩을 보는듯하다.레드라이트에 이어서,캐스팅만 쩌는 또하나의 졸작.당신의돈과시간을 조금더 소중히 하시라\n",
      "어렸을 때는 지능이 뒤떨어져 이 영화의 전체적인 흐름과 스토리를, 심지어 그 때문에 반전까지 못 느껴서 루즈하게 느껴졌지만, 나이가 들어 영화의 흐름과 반전을 느낄 정도의 약간은 성숙된(?)지능을 가지고 보니 영화의 완성도가 상당히 높다 여기게 되었다\n",
      "히나타 진짜 싫어하는데 영화가 급전개그렇고 더 라스트가 아니라 제목은 히나타의목도리인듯;;내용도 이상하고 작가가 육백화쯤에서 뜬금없이 번외로 히나타 동생내보내더니 극장판때문이였는듯.만화끝날때까지도 러브라인 확실하지않더니ㅋ작가겁나 배신감느껴짐.괜히 본듯\n",
      "현재2013년...퍼시픽림.슈퍼맨.배트맨.어밴져스등...컴퓨터그래픽의 절정을 보여주는 이시점에 컴퓨터그래픽은 제로....이럴수가....탈을쓰고 나오다니....무슨장난하는줄 알았다.1980년대나 나올법한 영화같지도 않은영화.돈주고보긴아까우니무료로보세요.\n",
      "걸작 공포영화마스터피스를 망쳐놓은 감독의 한심한 연출력...감독 존 무어...당신에게 오멘(666)의 저주가 있으리라.능력이 안되면,손대지를 말든가?제가 무슨 알프레드 히치콕이라고,엉뚱한 녀석.가서 다이하드6-본투비 와일드나 찍고있어~임마...(웃음)\n",
      "차인표는 드라마보다 유독 영화선택에 낮게 평가받는 이유가,이런 작은 선택들이모여,장강의대하를 이루기때문이다.차인표는 정말 영화시나리오 보는 안목이 정말...없다.육상효의습작.그래도 방가방가라고 가기위한 소중한 첫걸음이라고 보면,좀 견딜만할거라고 생각해\n",
      "7~8점정도가 적당. 재밌어요. 점수 올려주려고 10점줌. 써티데이즈오브나잇+데드캠프라 생각하면 됨. 극한 상황에서 생존하는 영화 좋아하시는분들께 추천합니다. 졸작 아니고 충분히 볼만한 작품. 시간이 짧은 만큼 아쉬운게 있긴하지만 전반적으로 괜찮아요.\n",
      "시나리오의 망작성에,진짜 갈라티아의눈물?도 사람처럼,눈물을 흘릴판이다.이수경의 발연기는 진짜 역사에 남을 수준...효리의 드라마출연외도이후에,사상 최고수준의 거의 대형사고 그 자체.내가 감독이라면,필름을 통채로 버렸을 꺼다.강혜정도 어설프고,진짜 졸작\n",
      "이런걸 보고 유식한 말로 데우스 엑스 마키나라고 한다.무슨일이 일어나도 이상하지 않은 영화.그게 이 영화의 궁극의 패착이다.아무것도 신기하지 않은게,신기한 점이랄까?보다보면,에라~될대로 되라...하고 진지하게 영화보기를 포기하는 지점이 반드시 생겨난다\n",
      "내인생 잊혀지지 않은 영화. 지금도 빠삐용 주제를 가끔 듣노라면 내가슴 깊은곳에 고독과 살아야겠다는 서러움이 절절하게 끓어오릅니다. 아마도 내 인생이 슷비슷비하지 않았나 생각됩니다. 물론 빠삐용하고 비교할 수 없지만 조금이나마 내인생을 말해주는 이영화\n",
      "평점이 이해 안된다.. 물론 형편없는 영화라는건 아닌데;; 죽은 자와의 소통이란 소재로 눈물도 좀 나오게 하는건 맞다. 근데, 이것 저것 짜 맞춘 느린 호흡의 영화로 끝에가서는 뭘 말하고자 했던건지 벙~ 찐다. 평점 무조건 10점 좀 때리지마시길...\n",
      "중국의 어거지 로마 마을 광관홍보영화. 중국에 있는 저 로마마을에 가면 로마에 있는 돈 받고 같이 사진찍어주는 로마병사코스프레를 따라한 중국할배들이 돌아다님 ㅋ 실화는 개뿔 학자들에 의하면 로마인들이 저 지역에 단체이주해 살았다는 역사적 근거는 전무함\n",
      "마치 하수구가 막혀 물이 내려가지 못하는 답답한 스토리?....같은 자리를 뱅뱅 도는 듯한 느낌...배우의 문제가 아니라 스토리가 문제 있는듯...밑에 10점 주신분들 주관적이기야 하겠지만...10점은 아닌듯...좀 시원하게 진행 좀 됐으면..질질질.\n",
      "소재는 기발했다. 하지만 그 이상의 뭔가를 보여주지못하고, 이 참신한 설정의 무대에서 놀고 있는 캐릭터들은 길을 못 찾고 어느 쪽으로 가야할지 허둥대는 상황만 보여준다. 사람들이 어둠속으로 사라질때 옷만 남겨놓듯 이 영화도 설정만 남겨놓고 사라진것같다\n",
      "감독 세르게이 보드로프...우베 볼이 감독 너에게 아따 행님요~하게 생겼다...(웃음)스티븐 시갈 영화들이,바람과함께 사라지다나,전쟁과평화처럼 보이게 하는 것도 재주 라면 재주...인디펜던스 데이 이후에 이 정도 발로 쓴 시나리오 정말 오랜만에 본다.\n",
      "이혜영 강남에서,10여년전에 한번 봤는데,007처럼,은색 재규어 몰고 다니더라.방송일만 하면,개나소나 다 끌고다니는 외제차 아직 한번도 못뽑아 봤으니,참.인생 왜 사나 싶다.그게 무슨 캡슐에서 뽑는,갸차폰 완구도 아니고,다들 재주도 좋네.쉽게 뽑으니.\n",
      "여기 호감순보면 순 친일파에 알지도 못하는 사무라이 역사를 말하고있네. 이 영화는 옛 사무라이의 더러운 것들을 미화시켜서 내논 영화입니다. 군사철학은 없고 단지 주군에 충성한 살인청부업자들이 모인 단체입니다. 글을 읽을줄 아는사람도 별로 없다고 하네요\n",
      "룸메이트 1기 그냥 그데로 했으면 좋겠는데 ㅠㅠㅠㅠ 1기 룸메이트 했던 사람들이 더 좋았는데 ㅠ이렇게 아쉽게 가버린다니 ㅠ 평생 잊지 못할거예요 ㅠ 그냥 1기때처럼 그데로 해줬으면 좋겠는데 ㅠ제발 우리곁에 떠나지마요 ㅠ안가면 안되나? 보고싶을 거예요ㅠ\n",
      "생뚱,엉뚱,갸우뚱한 상상력에 엉성하기 그지없는 전개, 한 마디로 실망 그자체입니다.제목은 진지한데 웃을래야 웃을 수 없는 일그러진 희극을 보는 것 같군요.마음을 따뜻하게 하는 드라마가 사라지고 말초신경만 자극하는 드라마가 판치는 시대의 일그러진 자화상\n",
      "멀쩡한 유역비 미모와,장난아닌,출연료만 아깝다~절세미녀 유역비 데려다가,OO 짓 하고 있다.한때는 아시아의 헐리우드 소리를 듣다가 한순간에 몰락해 버린,홍콩 영화판의,이유 있는 결과물.도학위룡이나,무간도 3부작의 발가락의때만큼만 해와봐.극장에서 봐준다\n",
      "처음에는 막장 소스를 신선하게 풀어가는 것 같아 잼있게 봤지만 3분의1을 넘어가자 막장중의 막장이 되어 실망스러웠음. 막장 소스를 이해할 수없는 상황에서 한꺼번에 퍼붓다가 맥없이 한큐에 해결되고 너무 유치함.그나마 초반의 신선함과 배우들의 연기에 3점\n",
      "진심 내가 왠만하면 영화들 비판 안하고 다 괜찮다 하는데 평점 첨 보고 오 괜찮나? 이러면서 보러갔었는데 진심 이렇게 뻔한 스토리에 지루한건 첨 이였음;; 영화관 나오면서 첨으로 별점 10점에 잼있어요~이러는 애들 죽일뻔 송혜교 탈세 할때부터 알아야했\n",
      "타짜는10점받아마땅하다.영화의모든부분이다재밌었다.캐릭터들은원작보다훨씬더매력적으로재현됐고,단역까지모든캐릭터가제몫을했다.긴이야기를아주 딱맞게압축했다.전국중고딩에게섯다열풍을몰고온,막판고니와아귀의설전을전국민이외우게만든작품.영화사에남을장면들이가득담겨있는선물세트\n",
      "최악의 영화입니다. 내용과 모든 게 삼류영화 입니다. 이종수씨의 잛은 컷에도 느껴지는 어색함과 아역배우의 너무 바른 발음이 연기쪽에서도 최악이었고여.. 내용도 처음 한시간 버려도 될만합니다. 다 버리면 좋겠지만 모든게급전개와 어울리지 않는 상황속대사들\n",
      "낯선 비율이 주는 파격. 익숙치않은 흑백이 주는 안정감. 이국적 풍취의 폴란드거리와 그시대. 화면아래 혹은 구석 어딘가에서 투영되는 차분하고 정적인 인물들의 움직임. 그 순간순간의 메세지. '나'를 찾아가는 한 존재의 각성 그리고 흔들리는 그 한걸음.\n",
      "복수라는 타이틀을 달지말던가. 복수영화.느와르 영화에서는 최소한의 규칙이있어 . 전개스타일 . 슬로우느낌 . 다좋다고 근데말야 복수가 복수다워야지 . 뭐냐고 원숭이같이 생긴 싸이코패스경찰서장이 주인공이네 . 복수를 해야할 라이언고슬링은 허접때기로나오네\n",
      "문제 의식의 제기에는 깊이가 있으나 현상만 나열하며 그쳤고....작가적 특유의 관점 또는 방향성이 젊으니까 아프다 정도의 아마추어적 한계도 보임...현 시점에서 관망해 보면..당시 박정희 정권의 의도적 정책에 의한 사회 현상 정도로 참고는 해 볼 정도\n",
      "봉준호작품은 마음에 깊게 남아 여러번 보았고, 미셸공드리의 작품은 결말은 좋았지만, 사족이 많았던것같아 조금 아쉽다. 레오까락스의 작품은 홀리모터스까지 보고 난뒤에야 이렇게 평점을 적지만, 드니라방의 연기 덕을 톡톡히 보았다고 생각한다. 좋았다 정말.\n",
      "국교때본거넹당시 책이먼저나왔었다네.중국은 일본 세균보듯싫어하지.걔들은 중화사상이라 지들 중심으로 지구가돈다고 생각하지. 정통한족도 아닌주제에.그냥 아시아 이민족 집합체 .일본도글치만, 떼넘들도더하다.오죽힌은 박정희가 탄압했긋나. 아시아의 유대이라고나.\n",
      "정당한 것을 얻기 위한 그들의 흥겨운 싸움이라고 보면 될까. 두리반과 인디밴드가 자신들의 권리와 존엄성을 지키기 위해 예술,(음악, 공연, 글 )으로 자신들의 의견을 피력하는 모습이 멋있었다. 영화관이 추워서 보는 내내 한겨울 두리반에 있는 느낌이었다\n",
      "이 영화를 가장좋아하는것은 20대여자 라고 되있고 가장 싫어하는 사람들이 20대 남성이다. 이로써 볼 수 있는것은 여자는 감정이 발달되있고 남자는 이성이 발달했다는 것이다. 감정이 발달되어 있으니 신이란 존재를 이성적, 논리적으로 판단하지 못하는것이다\n",
      "히든싱어 항상 챙겨봤었는데요! 모두 재밌었지만 이승환편이 정말 최고였습니다!! 저는 이승환님에 대해 잘 알지못했던 10대소녀인데요. 이번에 이승환편보고 전율을 느낀후 그 누구보다도 정말정말 진심으로 이승환님을 좋아하는 팬이 되었어요!!♡감사합니다^^♡\n",
      "영화속의 영화는 영화속의 현실이되고 그 현실이 영화로 만들어 졌다면 우리가 보는 영화는 어디에서부터 어디까지일까요? 현재속에 숨어있는 과거들 과거속에 숨어있었던 현재들 수많은 장치들을 찾아보는 것도 이 영화가 가지고 있는 즐거움 아닐까요? 좋았습니다.\n",
      "좀더스케일이커진영구.그이상도이하도아닌딱그만큼.영구특유의슬랩스틱은더이상통하지않는것같다.보는내내이영화를볼외국인들의반응이궁금하면서걱정되기도했음.나름대로스토리가짜여있지만,영구가여기에끼어있으니영몰입안됨;정신줄놓고그냥보려해도얼마못가서제정신을차리게되는안타까운영화.\n",
      "그래서 중국은 꿈을 펼치기에는,좋지않은 땅이라는 뜻이냐?그게 하루에100명가까이,15초마다,한건씩 살인이 일어나는,나라의국민이 할만한 주장이냐?유오성 닮은,츠차오의 발레공연장면만 볼만하다.어딘가 매카시즘의 반공유령이 떠다니고 있는듯한,기분이 드는 영화\n",
      "이민기 주연 = 부도 보증수표. 불변의진리ㅋㅋ 이민기의 주제넘은 의ㅈ감별논란만남은 희대의 졸작. 민기는 치졸하게 뒤에서 의ㅈ이네 뭐네하면서 더받았다고 열내지말고 제발 너나 똑바로하길바란다ㅎ 니가 왜 3.5억씩받음? 받아도 이태임이 받아야하는거아님?ㅋㅋ\n",
      "10년전인 2005년에 처음 봤는데 그때 봤을때의 충격이 전율이 아직도 생각난다. 왜 사람들이 대부를 20세기 최고의 영화이고 불후의 명작이라고 하는지 보고나서야 이해가 됐다. 총 5번 정도 본거 같은데 결혼하고 아버지가 되어서 또 한번 더 보고싶다.\n",
      "어설픈 잔재주, 한심한 얘기로.. 배우들만 낭비해버렸군! 로버트 알트만이 되고 싶었나? 여러 인물들의 스토리를 교차시켜 구성한다고 해서, 영화가 풍성해지는게 아니야. 유치한 억지 구성은 역겨움만 불러 일으키지. 캐치온 영화편성, 계속 이 따위로 할래!\n",
      "홍콩영화의 몰락...그 이후에도,어마어마한 부자로 잘 살아지는 사정봉.왕년의 액션스타 사현 선생님 친아들이라더만...박노식선생님 아들 박준규씨랑,비슷한 인생이라는 얘긴데,주머니사정은 전혀 비슷하지도 않네.루카스 아빠 사정봉이 훨씬 부자인 이유가 뭘까?\n",
      "나도 OO 북한가고싶을정도로....초호화 생활을 살던데.......이글보고 좌빨되는 극빈청소년들 증가할듯하다.....양선화는 아버지잘만난덕분에 북한 귀족계급으로서 초엘리트길을 걸어가고있는듯했다....자유고 나발이고 저런 파라다이스는 없는것같던데....\n",
      "프로젝트 니혼 제로 이치 닌교 츠가이(인형사) 프로젝트냐?오로라 공주와 손오공을 보아도,연쇄 살인범 이름으로,오로라 공주를 써먹고 싶고,바다의 왕자 마린보이를 보고도,마약거래상 이름으로,써먹고 싶은 인간들에게나,딱 어울리는 경지...한마디로,OO 영화\n",
      "티비에서 해준거보고 빡쳐서 들어와서 쓴다 주인공커플 하는일 하나두없음 쫓기며 돌아다니기만하고 싸움중인 군인 불러대면서 구해달라 난리치고 주인공답게 뭐 하는것없어 답답해 죽겠는데 쓸데없이 화면은 느리게잡고 마지막엔 아오뽁쳐 엔딩화면뜨는데 온가족이 말잃음\n",
      "솔직히 솔직히 혁.잭슨.성재.엔은아이돌인데진심 가명도 대충짓고 엔오빠두 가명이 차돌백이가 뭔지.형돈오빠는 방송인데 옷도대충 침대에누워있고 보는 시청자들의 대한 예의도 아니고ㅡㅡ 보면서 아이돌 오빠들 불쌍했음 안무가도 없고 예산이 없으면 하시질 말던가여\n",
      "정말불쾌한영화, 똥 만질줄 몰라서 사람들이 똥을 안만지는게 아닙니다 더러워서안만지는거지.적나라한표현으로감독딴엔표현면에서우쭐했겠지만그건 작품성이 아닌 똥을주물럭거리는 표현밖에 아닌겁니다. 감독이요구한 이런저질표현때문에 이은주씨가 후유증을 앓은거다감독양반\n",
      "나는 나쁘지 않게 봤다만 대부분의사람들은 뭔가 있어보이면 명작이라고 칭송한단 말이지 니들이 이해못해서 재미없다고 하는 정신승리를 곁들여 말이야 연출은 참신했으나 복선이 진부하고 각 플롯마다 연관성이 부족했다 뭐 이것도 감독이 설계했다하면 할말 없겠지만\n",
      "특별하지 않은 특별한 사랑..이토록 말없고, 또 단순한 내용임에도 글을 읽듯 또박또박 장면들을 읽어 나가게 하는 묘한 매력의 영화. '이별연습'에서의 리첸의 울음은 내가 본 가장 아름다운 여성의 울음이다. 미처 놓친 감정을 읽기위해 다시 봐야할 영화.\n",
      "직설적으로 남자분은 연기력이좀...떨어진대다 대사까지 오글거려서 몰입을 완전 방해했다. 장면하나하나에 깨알같은정성(연출)없었고 촬영기간이늘어져서인지 얼른끝내고 싶어하는느낌이 들었다 . 하루에 영화한편씩챙겨볼정도로 팬인데 이건좀 너무했다 한효주가 아깝다\n",
      "1995년인가? mbc에서 11시에 방영했는데, 뭐지 하고 그냥 봤다. 근데 감동이 그냥 감동이 그리고 1년 후인가? 또 방송했다. 비디오테잎으로 녹화해 놓고 보고 또 보고 녹화한 테잎을 다시 녹화해 소장하고 있었다. 근데 몇 해 전 찾아보니 곰팡이가\n",
      "말이 필요없는 일대기영화. 유명작가의 일대기인지라 문학적이고 암울한 현실을 신랄하게 비판하지만 그 안의 인간관계의 아름다움도 버리지 않는다. 주인공의 동성애 성적망상도 가감없이 대담한묘사. 하비에르 바르뎀은 금세기의 배우로 불릴만하다. 조니뎁은 단역.\n",
      "REC1, 2는 제목 그대로 카메라로 녹화하는 1인칭 시점으로 나오지만 3는 아에 컨셉자체를 팔아먹고 피식도 안할만큼 재미없는 개그만 계속 나오고 뜬금없이 여주는 무슨 데드라이징 주인공마냥 하이힐 신고 하이킥에 전기톱에 좀비무쌍하고 엔딩은 개똥망고어물\n",
      "내용 콘스탄틴 뱃김.엑소시스트 명장면 뱃김(오마주라 하기엔 개허접).특수분장 1980년대 초반 수준...cg는 울트라맨 보다 후짐.연기는 영어 못하는 사람이 봐도 발연기느낌. 한 화면에 3명이상 잘안나옴.(총출연진이20명 될까 싶음) 개봉영화인게 신기\n",
      "이딴걸드라마라고썼냐 수습할수없으면걍친자녀아니면되고 간단하네 얼굴을바꿨으면 결말이라도잘정리하던가 가족땜에 밥먹을때할수없이보는데 토나올것같아서밥도못먹는다 볼때마다 오프닝이며대사며 하나하나유치하고어이가없어서웃는다ㅋㅋㅋㅋ제~발빨리끝나고 더이상이딴드라마쓰지마라\n",
      "와 이 영화 개봉한지 5년이 더 지난 지금 봤는데 지금 최근 영화들보다도 구성도 재미도 훨씬 탄탄하고 재밌네...이런 수작을 지금이라도 보다니.. 딱 디즈니 애니 구성을 영화로 잘 만들어 논것같음..질렌할 확실히 이때보다 지금이 연기는 훨씬 늘었긴한듯\n",
      "175분이 너무나 짧게 느껴졌다.명대사며 명언이며 연기며 캐릭터까지 잊을 수가 없는 영화.초반부터 교훈적이 말들이 나와 정말 중독되었다.원래 봤던 영화를 또 보면 지루하지만 이 영화는 끝까지 보게 하는 영화다.내가 느와르를 좋아하게 되는 계기.책도 짱\n",
      "0점이 없네...개인적으로 평소 서우 드라마에서 연기 못한다는 느낌은 안들었는데 이건 완전 발연기 그리고 일부러 입술 내미는듯.. 입술 두꺼운 연예인들 되게 섹시하고 예쁜데 애는 이상함.. 일반인이 카메라 앞에서 처음 연기하는 듯함... 서우 완전 실\n",
      "보다가 어처구니가 없어서 존쿠삭이나 애드리안브로디 를 삼류로 만드는 감독의 능력 일단 각본이 말이 안되는게 너무 많다 성룡이 어렸을때 자기 동생 우는걸 막다가 죽이고 또 그거에 분해서 장군을 칼로 찌른거 맞지? 사실 그냥 틀어놓고 자꾸 딴일을 하게돼서\n",
      "파이트클럽을 안봤다면 재미있을수도 있었겠지만. 멀쩡하고 성실한 사람이 정신병자 취급 받을만큼 금융계에 야비한 인간들이 많다는 것에는 절대 공감한다. 상투성으로만 취급하기엔 부모가 아프고 직장에서 함정에 빠지고 하는것은 누구에게 닥칠지 모르는 보편성이다\n",
      "카이지를 뺏겻느니 라이어게임을 뺏겻느니 하는데. 그런 포맷의프로그램은 한번나오고나오지말아야하는가???전혀다른 것만나와야 한다고? 난 이런류 다 좋아한다. 근데 뭐 시청자를 우롱한다?개인의 생각을 모든 시청자를 대표하지마라. 거지같은블로거에게하는말입니다\n",
      "별 빵개는 없나요? 드라마 보다가 빡쳐서 평점쓰기는 또 처음이네요 작가분 정신과 상담 좀 받아보세요 진짜 배우들이 아까운 드라마...등장인물들이 죄다 미치광이들이네요 밑에 분 말처럼 한사장이랑 윤재아빠 빼고 다 미쳤어 상식적으로 이해할 수 없는 드라마\n",
      "정말 잘 만든영화. 렘수면이라든지 다소 어려운 용어도 나오며 어린이들은 좀 어려울 수 있으니깐 줄거리는 숙지하고 보세요. 리뷰 추천된거 한번 훑어보시고 보시면 이해가 빠를듯합니다. 강력추천!!! 누구나 꿈속에서는 다른사람이 되고 싶어하는 욕망도 잘표현\n",
      "유태인,흑인,동성애자들은 싫어할만한,걸작...(웃음)근데,난 유태인도,흑인도 아니고,동성애자는 더더욱 아닌데,왜 이 영화가 지루했지?크리스틴이 너무 낮설다.톰 크루즈가 아주 낮설었던,매그놀리아는 아주 대박 좋았는데 말이지.크리스틴이 다른사람처럼 느껴져\n",
      "한국인비하하는 영화가 뭐가 좋다는거지? 인종우월주의를 따지자는게 아니라 음악으로서 즐거움을 주는 영화면그런 영화답게 음악적 요소에 집중해야지 개그부분에 욕심을 너무 부려도 도가 지나쳤다 한국계미국인배우도 굳이 동양을 까내려가며 연기하고싶은지 의문이다.\n",
      "솔직히 제목때문에 호기심 땡겨서 대충 대충 봤는데, 기대이상이다. 평점 엉망으로 준 놈들. 다른 영화보고도 함부러 평가 하지마라. 영화 볼 줄도 모르는 놈들. 그러니 네이버 평점이 엉망이지. 그냥 닥치고 책많이보고 철학 공부좀 해라. 함부러 나 대지마\n",
      "데스노트의 열렬한 팬인 나로써는 이 작품을 최악으로 볼수밖에 없다.심리전도 없고 반전도 없고 유일하게 마츠마야 켄이치 배우님의 연기실력 덕분에 이 정도는 한것이다.지금이라도 데스노트 속편이 나오는건 환영이지만 이런 데스노트와 대립이 없는 속편은 사양.\n",
      "전지현 나오는영화는 그닥이라안보다가..암살본후 급궁금해져서본영화..하정우랑 한석규는 뭐 갓오브갓이구..전지현이 이토록연기를잘하는지 몰랐음...씨엡만찍지말구 영화좀다작으로했음 여자하정우는됐을텐데..전지현다시보게되는영화..내용도좋구..북한말은 잘못알아듣겠\n",
      "2004년 이 드라마에 빠져서 헤어나오질 못했고 2005년까지도 후유증으로 고생했던 기억이 생생하다 10년이 지났지만 그 지금까지 봐왔던 그 어떤 드라마에 뒤쳐지지 않은 명작이다 연기,배우,시나리오,OST, 아름다운풍경 모든게 최고다 평점10점도모잘라\n",
      "콘티짜는데 들어간 종이가 아깝다. 어찌 90년대 특촬물에 쌈마이 cg 처리를 저딴식으로 할수있는지 정말 궁금하다. 지금와서 왜 dvd 발매 안하는지 알거같은 영화. 구성, 연출, 카메라 앵글, 그래픽, 심지어 클리셰에 허덕이는 스토리라인 모든것이 아류\n",
      "와 ...진짜 쓰레기 김우빈의 쓸데없는 인상에 같이 인상써지는 불편함 완젼 미스 캐스팅 나오는 조연들 마다 어찌 그리 한심하고 쓰레기 같은 것들을 데려다 썼는지..답답하다 진짜 .내용도 최악 ..유오성 믿고 보는 배우 였는데..피캬츄 문신은 또 뭐야.\n",
      "이채영,완전채 이쁘고 귀엽고 가능성도 충분히있다고생각하지만 모든것을다걸고나온 사람들을 밟고올라갈만큼 뛰어나다고생각하지않습니다. 솔직히 홍정희,썸띵 노래들을때 진짜 소름끼칠만큼 감동이전해졌고 연애하는느낌이들정도로좋았어요. 심사의 기준이 뭔지 정말궁금해요\n",
      "나이 30줄을 바라보는 지금 어릴적 재밌게 본 홈무비 하면 나홀로집에와 꼬마유령캐스퍼. 어렸을때 봤는데도 아직도 스토리가 기억이 난다. 누가 영리하지 않은 영화라고 욕하는데, 아동무비에 뭘 더 바라나. 다큰 어른의 추억 한켠에 남아있으니 그걸로 충분.\n",
      "유년기의추억인 바람의검심만화를 영화로보니 감회가새롭고 연출 배우들이 자연스럽고 정말 원작을보는것같다. 내용은 애니중 4분의1에피소드지만 평이할수도잇지만 여러모로 벅찬감동이느껴진다 다만 크게크게내용을 나눠도되면 좋겟고 성상편으로 결말각색니정말로 기대된다\n",
      "오리지날을 잔인하게 난도질하는,거장의 최악의한수...샤론스톤의 글로리아는,마돈나의 마돈나(성녀)역할을 보는 것만 같다.그정도로 못봐줄 지경이었다는 얘기다.터미네이터의 남자주인공 터미네이터처럼,빵칼로 눈을 파내고 싶었을 정도.몸매만은 정말 죽이더만...\n",
      "8점을 줬었는데 자꾸 생각이 나서 다시 들어와서 9점! 일본 코미디 영화의 정석같다. 주연의 오버 연기도 좋았고 느끼는 점도 많았다. 무엇보다 매력적인 마이코의 모습과 말투(도스~)가 자꾸 머리에 맴돈다. 유쾌한 영화!(2015.06.28 14:18)\n",
      "\"언제 보아도 감동적이고 가슴 찡해지는 예수님 이야기. 얼마 전에 감상한 \"\"손 오브 갓\"\"과 비교해 보면영화의 배경과 연출방식은 상당히 고전적이다. 하지만 \"\"손 오브 갓\"\"이 왠지 더 감동적이라는 생각이 든다.손~ 이 더 성경 말씀을 잘 표현했다\"\n",
      "돈이걸리니깐 연예인들도 본성 나오네요 김풍씨 여기서 첨봤는데 당신 인간성에 매우 놀랍네요 김구라 면전에 대고 좋다고소리지르고 ㅉㅉ 지가 그렇게 붙던 홍진호 떨어지게 생겼는데 글케 분위기 파악 못하나? 검색하니깐 하고다니는짓도 또라이드만 면상부터 재섭음\n",
      "왠만하면 평점안남기는대 참나 ㅋㅋ너무햇다 제목만 대작삘이고 영화는 OOO수준 ㅋㅋ용몇번나오지도않고 용같지도않고 작살몇번던지고 어설푼연기력에 스케일도작고 줄거리역시 지루하다 박진감도 전혀없는 티비에서해주는 주말에영화급에도 못낀다 ㅋ진짜 평점높게준애들알바\n",
      "영화무대가 맨홀밑이거나,맨홀위...근데 문제는,상영시간내내라는거...영화 끝날때까지,맨홀밑이거나,맨홀위거나,한치도 안 벗어남...보고 있는 사람 도는 거지...모니터로 봤으니까,참은거지,극장가서 봤으면,아마 돌아버릴듯...진짜 극장가서 본 사람 불쌍타\n",
      "키에누 리브스.토머스 앤더슨.매트릭스의네오.지하세계로,몰락하다.모피어스,로렌스 피시번처럼,반장님으로나,풀릴것이지.사뮤엘 잭슨,윌 스미스에게는,이런일이 안 일어나는 이유.갑자기 그것이 궁금.별다른 재미도 없는 시나리오.설마 용돈이 궁핍해선 아닐테고...\n",
      "정당화시킬려고 막판에 다시 도 바람피웠던걸로 포장 해서 각자각자 어울리는사람과사는걸로 마무리된것같은데 초반에 덱스가 레이첼이랑 바람난거볼때 욕이수두룩하게나 왔음 그뒤로 레이첼의모든게 가식적이고 얄미움 뺏을껀다뺏고 착한척ㅋㅋ ,이런친구사귈까봐 무서운영화\n",
      "처음엔 나인과 다르게 왜이렇게유치하지 싶었는데 후반부로 올수록 정말 재밌어지네요 과거부터 거슬러오는 인연?도 충분히개연성있고 억지스럽지않은데다가 스토리도탄탄하고요. 멜로씬이많이없어서 아쉽지만ㅎㅎ 남은 2회는 정치얘기보단 달달한사랑얘기가많았음 좋겠어요~\n",
      "배경음을 최대한 생략했음이 처음엔 어색했으나 나중엔 최고의 효과였음을 알았다. 영화상의 이야기지만 악마는 보았다도 그렇고, 타인에게 고통/죽음을 주면서 그게 즐겁고 좋으면 싸이코고 그게 멘탈 고통과 후유증을 안겨주면 정상인인가.. 씁쓸한 잔혹 복수..\n",
      "만화책 3번 봤는데 원작을 잘 살린 영화라 생각합니다. 시장의 연설에서 인간이 벌레가 아닌 짐승이라 기생수라 말한 장면, 작가의 말에 나온 주인공이 쓰러진 고토를 살려주려다 다시 죽인 장면은 책보다 더 와닿았습니다. 모성애를 강조한 것도 감동이었습니다\n",
      "박은혜만 아까워...김해숙여사는,계속 영화나 하시는게,더 정신건강에 좋을듯...인기도 없는게 벌써70회이상 방송중이라니...아침출근시간을 여지없이 망쳐놓는,몇 안되는 킬러프로그램.준석이 아버지 주현선생님을 아주 푹푹 썩히는구나.누가 젓갈이라도 담구나?\n",
      "김세윤 최강희 이동진 이화정 << 무슨 영화 얼마나 존문가랍시고 지들멋대로 평점쳐날리네 한국영화에는 돈쳐받고 10점날리고 돈쳐받고 외화에 평점테러하는년들 쓰레기년들 자살추천한다 내가 니들보다 영화더알아 쓰레기년들 이런명화에 저따위개소리를 입에재갈물린다\n",
      "차라리 애니 그 남자ㅡ그 여자의 사정을 한번 더 보고 만다...이토록 창의력없는 제목에 걸맞지 않는,제법 매력 통통튀는 여배우.그러나 나는,네모토 하루미같은 거유 타입을 좋아하므로,별 관심 없음.수정이는,정답입니다~의 수정이나,여배우 임수정이 제일이지\n"
     ]
    }
   ],
   "source": [
    "check_sentence_with_length(raw, 140)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-impact",
   "metadata": {},
   "source": [
    "## 중복 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "specified-desire",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T08:55:28.658952Z",
     "start_time": "2021-04-20T08:55:28.083047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 194543\n",
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 146\n",
      "문장의 평균 길이: 36\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 중복 제거\n",
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "cleaned_corpus = list(set(raw))  # set를 사용해서 중복을 제거합니다.\n",
    "print(\"Data Size:\", len(cleaned_corpus))\n",
    "\n",
    "for sen in cleaned_corpus:\n",
    "    sen = str(sen)\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(cleaned_corpus))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in cleaned_corpus:   # 중복이 제거된 코퍼스 기준\n",
    "    sen = str(sen)\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-bidder",
   "metadata": {},
   "source": [
    "## 데이터 범위 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "comic-mount",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T08:55:36.337077Z",
     "start_time": "2021-04-20T08:55:35.959460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_len = 80\n",
    "min_len = 0\n",
    "\n",
    "# 길이 조건에 맞는 문장만 선택합니다.\n",
    "filtered_corpus = [s for s in cleaned_corpus if (len(s) < max_len) & (len(s) >= min_len)]\n",
    "\n",
    "# 분포도를 다시 그려봅니다.\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in filtered_corpus:\n",
    "    sen = str(sen)\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-festival",
   "metadata": {},
   "source": [
    "# SentencePiece 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "portable-greensboro",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T08:56:57.107461Z",
     "start_time": "2021-04-20T08:56:04.851870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 aiffel-dj24 aiffel-dj24 298410  4월 20 17:56 korean_spm_4k.model\r\n",
      "-rw-r--r-- 1 aiffel-dj24 aiffel-dj24  64365  4월 20 17:56 korean_spm_4k.vocab\r\n",
      "-rw-r--r-- 1 aiffel-dj24 aiffel-dj24 374971  4월 20 17:56 korean_spm_8k.model\r\n",
      "-rw-r--r-- 1 aiffel-dj24 aiffel-dj24 144310  4월 20 17:56 korean_spm_8k.vocab\r\n",
      "-rw-r--r-- 1 aiffel-dj24 aiffel-dj24 296979  4월 20 17:56 korean_spm_bpe_4k.model\r\n",
      "-rw-r--r-- 1 aiffel-dj24 aiffel-dj24  50190  4월 20 17:56 korean_spm_bpe_4k.vocab\r\n",
      "-rw-r--r-- 1 aiffel-dj24 aiffel-dj24 370498  4월 20 17:56 korean_spm_bpe_8k.model\r\n",
      "-rw-r--r-- 1 aiffel-dj24 aiffel-dj24 115709  4월 20 17:56 korean_spm_bpe_8k.vocab\r\n",
      "-rw-r--r-- 1 aiffel-dj24 aiffel-dj24 375094  4월 20 11:24 korean_spm.model\r\n",
      "-rw-r--r-- 1 aiffel-dj24 aiffel-dj24 144530  4월 20 11:24 korean_spm.vocab\r\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "temp_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp'\n",
    "\n",
    "vocab_size_8k = 8000\n",
    "vocab_size_4k = 4000\n",
    "\n",
    "with open(temp_file, 'w') as f:\n",
    "    for row in filtered_corpus:   # 이전 스텝에서 정제했던 corpus를 활용합니다.\n",
    "        f.write(str(row) + '\\n')\n",
    "\n",
    "# 모델 타입 : unigram / 어휘 사전 크기 : 8,000 \n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=korean_spm_8k --vocab_size={}'.format(temp_file, vocab_size_8k)    \n",
    ")\n",
    "\n",
    "# 모델 타입 : bpe / 어휘 사전 크기 : 8,000 \n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_type=bpe --model_prefix=korean_spm_bpe_8k --vocab_size={}'.format(temp_file, vocab_size_8k)    \n",
    ")\n",
    "\n",
    "# 모델 타입 : unigram / 어휘 사전 크기 : 4,000\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=korean_spm_4k --vocab_size={}'.format(temp_file, vocab_size_4k)    \n",
    ")\n",
    "\n",
    "# 모델 타입 : bpe / 어휘 사전 크기 : 4,000 \n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_type=bpe --model_prefix=korean_spm_bpe_4k --vocab_size={}'.format(temp_file, vocab_size_4k)    \n",
    ")\n",
    "\n",
    "#위 Train에서  --model_type = 'unigram'이 디폴트 적용되어 있습니다. --model_type = 'bpe' 로 옵션을 주어 변경할 수 있습니다.\n",
    "\n",
    "!ls -l korean_spm*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "complimentary-stress",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T09:06:00.170807Z",
     "start_time": "2021-04-20T09:06:00.149153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1602, 10, 425, 15, 1404, 10, 138, 16, 4]\n",
      "['▁아버지', '가', '방', '에', '들어', '가', '신', '다', '.']\n",
      "아버지가방에들어가신다.\n"
     ]
    }
   ],
   "source": [
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('korean_spm_8k.model')\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoding\n",
    "tokensIDs = s.EncodeAsIds('아버지가방에들어가신다.')\n",
    "print(tokensIDs)\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoded pieces\n",
    "print(s.SampleEncodeAsPieces('아버지가방에들어가신다.',1, 0.0))\n",
    "\n",
    "# SentencePiece를 활용한 encoding -> sentence 복원\n",
    "print(s.DecodeIds(tokensIDs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-sessions",
   "metadata": {},
   "source": [
    "# Tokenizer 함수 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "hazardous-documentary",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T09:06:46.980779Z",
     "start_time": "2021-04-20T09:06:46.965476Z"
    }
   },
   "outputs": [],
   "source": [
    "def sp_tokenize(s, corpus):\n",
    "\n",
    "    tensor = []\n",
    "\n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "\n",
    "    with open(\"./korean_spm.vocab\", 'r') as f:\n",
    "        vocab = f.readlines()\n",
    "\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "\n",
    "        word_index.update({idx:word})\n",
    "        index_word.update({word:idx})\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='pre',maxlen=80)\n",
    "\n",
    "    return tensor, word_index, index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "organic-question",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T09:06:48.218226Z",
     "start_time": "2021-04-20T09:06:48.207119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0  706 3224 6292  559  827 6261]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0 1772 2262  308  336 6269  164 7621   15    7]]\n"
     ]
    }
   ],
   "source": [
    "#sp_tokenize(s, corpus) 사용예제\n",
    "\n",
    "my_corpus = ['나는 밥을 먹었습니다.', '그러나 여전히 ㅠㅠ 배가 고픕니다...']\n",
    "tensor, word_index, index_word = sp_tokenize(s, my_corpus)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "thrown-holiday",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T09:07:05.258265Z",
     "start_time": "2021-04-20T09:07:01.777210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195339, 80)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.Load('korean_spm.model')\n",
    "train_test, word_index, index_word = sp_tokenize(s, raw)\n",
    "train_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "transparent-elder",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T09:07:08.271081Z",
     "start_time": "2021-04-20T09:07:08.241415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96182, 80)\n",
      "(96182,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분할\n",
    "X_train = train_test[:146182]\n",
    "X_test = train_test[146182:]\n",
    "\n",
    "y_train = np.array(list(train_data['label']))\n",
    "y_test = np.array(list(test_data['label']))\n",
    "\n",
    "# validation set 50000건 분리\n",
    "x_val = X_train[:50000]   \n",
    "y_val = y_train[:50000]\n",
    "\n",
    "# validation set을 제외한 나머지 \n",
    "partial_X_train = X_train[50000:]  \n",
    "partial_y_train = y_train[50000:]\n",
    "\n",
    "print(partial_X_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-portfolio",
   "metadata": {},
   "source": [
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "enclosed-spectrum",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T09:07:47.200335Z",
     "start_time": "2021-04-20T09:07:46.966477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,322,821\n",
      "Trainable params: 2,322,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다.\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수\n",
    "\n",
    "# model 설계\n",
    "model1 = keras.Sequential()\n",
    "model1.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model1.add(keras.layers.LSTM(word_vector_dim))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "model1.add(keras.layers.Dense(10, activation='relu'))\n",
    "model1.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-discussion",
   "metadata": {},
   "source": [
    "# 모델 훈련 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cheap-workshop",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T09:09:25.054355Z",
     "start_time": "2021-04-20T09:08:18.601533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "188/188 [==============================] - 17s 70ms/step - loss: 0.5515 - accuracy: 0.7175 - val_loss: 0.3475 - val_accuracy: 0.8492\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 13s 67ms/step - loss: 0.3162 - accuracy: 0.8655 - val_loss: 0.3359 - val_accuracy: 0.8519\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 13s 67ms/step - loss: 0.2846 - accuracy: 0.8803 - val_loss: 0.3340 - val_accuracy: 0.8535\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 12s 64ms/step - loss: 0.2561 - accuracy: 0.8907 - val_loss: 0.3523 - val_accuracy: 0.8527\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 12s 63ms/step - loss: 0.2245 - accuracy: 0.9015 - val_loss: 0.3611 - val_accuracy: 0.8505\n"
     ]
    }
   ],
   "source": [
    "model1.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=5  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history1 = model1.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "floral-season",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T09:12:43.176385Z",
     "start_time": "2021-04-20T09:12:39.026673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 4s - loss: 0.3701 - accuracy: 0.8467\n",
      "[0.37012988328933716, 0.8466545939445496]\n"
     ]
    }
   ],
   "source": [
    "results = model1.evaluate(X_test,  y_test, verbose=2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "prerequisite-winner",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T09:12:54.872817Z",
     "start_time": "2021-04-20T09:12:54.856780Z"
    }
   },
   "outputs": [],
   "source": [
    "def pipeline(spms, vocab):\n",
    "    s = spm.SentencePieceProcessor()\n",
    "    s.load(spms)\n",
    "    train_test, word_index, index_word = sp_tokenize(s, raw)\n",
    "    X_train = train_test[:146182]\n",
    "    X_test = train_test[146182:]\n",
    "\n",
    "    y_train = np.array(list(train_data['label']))\n",
    "    y_test = np.array(list(test_data['label']))\n",
    "\n",
    "    # validation set 50000건 분리\n",
    "    x_val = X_train[:50000]   \n",
    "    y_val = y_train[:50000]\n",
    "\n",
    "    # validation set을 제외한 나머지 \n",
    "    partial_X_train = X_train[50000:]  \n",
    "    partial_y_train = y_train[50000:]\n",
    "    \n",
    "    vocab_size = vocab    # 어휘 사전의 크기입니다.\n",
    "    word_vector_dim = 200  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "    # model 설계\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "    model.add(keras.layers.LSTM(word_vector_dim))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "    model.add(keras.layers.Dense(10, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    epochs=5  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "    history = model.fit(partial_X_train,\n",
    "                        partial_y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=512,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        verbose=1)\n",
    "    results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "    print(results)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "forbidden-settle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T09:18:56.094768Z",
     "start_time": "2021-04-20T09:15:17.162667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 200)         1000000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,322,821\n",
      "Trainable params: 1,322,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 13s 64ms/step - loss: 0.5741 - accuracy: 0.7049 - val_loss: 0.3684 - val_accuracy: 0.8387\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 11s 60ms/step - loss: 0.3562 - accuracy: 0.8462 - val_loss: 0.3642 - val_accuracy: 0.8400\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 11s 60ms/step - loss: 0.3380 - accuracy: 0.8551 - val_loss: 0.3509 - val_accuracy: 0.8449\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 12s 63ms/step - loss: 0.3247 - accuracy: 0.8595 - val_loss: 0.3487 - val_accuracy: 0.8470\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 12s 65ms/step - loss: 0.3058 - accuracy: 0.8691 - val_loss: 0.3414 - val_accuracy: 0.8487\n",
      "1537/1537 - 5s - loss: 0.3497 - accuracy: 0.8432\n",
      "[0.3497273921966553, 0.8432369828224182]\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 200)         1000000   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,322,821\n",
      "Trainable params: 1,322,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 13s 65ms/step - loss: 0.5401 - accuracy: 0.7202 - val_loss: 0.3662 - val_accuracy: 0.8373\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 12s 65ms/step - loss: 0.3489 - accuracy: 0.8488 - val_loss: 0.3515 - val_accuracy: 0.8439\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 12s 64ms/step - loss: 0.3231 - accuracy: 0.8576 - val_loss: 0.3456 - val_accuracy: 0.8481\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 12s 63ms/step - loss: 0.3005 - accuracy: 0.8678 - val_loss: 0.3432 - val_accuracy: 0.8498\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 12s 65ms/step - loss: 0.2719 - accuracy: 0.8815 - val_loss: 0.3411 - val_accuracy: 0.8500\n",
      "1537/1537 - 4s - loss: 0.3511 - accuracy: 0.8436\n",
      "[0.3510739803314209, 0.8436235189437866]\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,322,821\n",
      "Trainable params: 2,322,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 15s 71ms/step - loss: 0.5592 - accuracy: 0.7070 - val_loss: 0.3558 - val_accuracy: 0.8458\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 13s 70ms/step - loss: 0.3196 - accuracy: 0.8642 - val_loss: 0.3400 - val_accuracy: 0.8491\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 13s 72ms/step - loss: 0.2832 - accuracy: 0.8811 - val_loss: 0.3393 - val_accuracy: 0.8522\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 14s 74ms/step - loss: 0.2515 - accuracy: 0.8955 - val_loss: 0.3507 - val_accuracy: 0.8507\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 14s 74ms/step - loss: 0.2248 - accuracy: 0.9062 - val_loss: 0.3736 - val_accuracy: 0.8470\n",
      "1537/1537 - 5s - loss: 0.3845 - accuracy: 0.8430\n",
      "[0.3844735622406006, 0.8429928421974182]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2a842f9fd0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline('korean_spm_4k.model',5000)\n",
    "pipeline('korean_spm_bpe_4k.model',5000)\n",
    "pipeline('korean_spm_bpe_8k.model',10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-seventh",
   "metadata": {},
   "source": [
    "# KoNLPy 형태소 분석기를 사용한 모델과 성능 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-resolution",
   "metadata": {},
   "source": [
    "## Mecab 호출 및 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "australian-zoning",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T10:19:27.237591Z",
     "start_time": "2021-04-20T10:19:08.463696Z"
    }
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "#미리 정의한 불용어\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다'] \n",
    "num_words = 10000\n",
    "\n",
    "# 함수 기능\n",
    "# 데이터의 중복 제거   \n",
    "# NaN 결측치 제거   \n",
    "# 한국어 토크나이저로 토큰화   \n",
    "# 불용어(Stopwords) 제거   \n",
    "# 사전word_to_index 구성   \n",
    "# 텍스트 스트링을 사전 인덱스 스트링으로 변환   \n",
    "# X_train, y_train, X_test, y_test, word_to_index 리턴   \n",
    "def load_data(train_data, test_data, num_words=num_words):\n",
    "    # 중복, 결측치 제거\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "\n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(num_words-4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    # 사전 구성\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "\n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "    # 변환 text to index\n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "\n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "    \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "expected-stocks",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T10:19:31.043196Z",
     "start_time": "2021-04-20T10:19:31.033364Z"
    }
   },
   "outputs": [],
   "source": [
    "# index to text 사전\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "decreased-flash",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T10:19:36.557988Z",
     "start_time": "2021-04-20T10:19:36.545033Z"
    }
   },
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-rugby",
   "metadata": {},
   "source": [
    "## 문장 길이 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "instant-herald",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T10:19:54.655689Z",
     "start_time": "2021-04-20T10:19:54.601884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  15.969376315021577\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  12.843535456326455\n",
      "pad_sequences maxlen :  41\n",
      "전체 문장의 0.9342988343341575%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(X_train) + list(X_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 최대 길이를 (평균 + 2*표준편차)로 한다  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-basketball",
   "metadata": {},
   "source": [
    "## 패딩 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "outstanding-refrigerator",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T10:20:01.279211Z",
     "start_time": "2021-04-20T10:20:00.481561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 41)\n"
     ]
    }
   ],
   "source": [
    "# 패딩 추가 (using keras.preprocessing.sequence.pad_sequences)\n",
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', # 혹은 'post'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', # 혹은 'post'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-nightlife",
   "metadata": {},
   "source": [
    "## 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "immediate-parts",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T12:45:53.248035Z",
     "start_time": "2021-04-20T12:45:53.035865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 8)                 1608      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,322,417\n",
      "Trainable params: 2,322,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(8,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(word_vector_dim))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-platinum",
   "metadata": {},
   "source": [
    "## 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "verified-hearts",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T12:45:55.330941Z",
     "start_time": "2021-04-20T12:45:55.328101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96182, 41)\n",
      "(96182,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 50000건 분리\n",
    "x_val = X_train[:50000]   \n",
    "y_val = y_train[:50000]\n",
    "\n",
    "# validation set을 제외한 나머지 \n",
    "partial_X_train = X_train[50000:]  \n",
    "partial_y_train = y_train[50000:]\n",
    "\n",
    "print(partial_X_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-detective",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "radio-verse",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T12:46:36.195357Z",
     "start_time": "2021-04-20T12:45:57.401124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "188/188 [==============================] - 9s 41ms/step - loss: 0.5338 - accuracy: 0.7297 - val_loss: 0.3488 - val_accuracy: 0.8469\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 7s 40ms/step - loss: 0.3180 - accuracy: 0.8668 - val_loss: 0.3416 - val_accuracy: 0.8493\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 7s 40ms/step - loss: 0.2848 - accuracy: 0.8809 - val_loss: 0.3385 - val_accuracy: 0.8531\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 8s 40ms/step - loss: 0.2515 - accuracy: 0.8956 - val_loss: 0.3464 - val_accuracy: 0.8534\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.2175 - accuracy: 0.9089 - val_loss: 0.3631 - val_accuracy: 0.8529\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=5  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "integral-workshop",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T12:47:34.178776Z",
     "start_time": "2021-04-20T12:47:30.861931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.3704 - accuracy: 0.8453\n",
      "[0.3703998923301697, 0.8453119397163391]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-spectrum",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-estonia",
   "metadata": {},
   "source": [
    "# 성능 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-yugoslavia",
   "metadata": {},
   "source": [
    "- __SentencePiece : Unigram / 8k__  \n",
    "loss: 0.3701 - accuracy: 0.8467  \n",
    "[0.37012988328933716, 0.8466545939445496]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-rally",
   "metadata": {},
   "source": [
    "- __SentencePiece : Unigram / 4k__  \n",
    "loss: 0.3497 - accuracy: 0.8432  \n",
    "[0.3497273921966553, 0.8432369828224182]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-berry",
   "metadata": {},
   "source": [
    "- __SentencePiece : BPE / 8k__  \n",
    "loss: 0.3511 - accuracy: 0.8436  \n",
    "[0.3510739803314209, 0.8436235189437866]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-unknown",
   "metadata": {},
   "source": [
    "- __SentencePiece : BPE / 4k__  \n",
    "loss: 0.3845 - accuracy: 0.8430  \n",
    "[0.3844735622406006, 0.8429928421974182]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-registrar",
   "metadata": {},
   "source": [
    "- __KoNLPy : Macab / 10k__  \n",
    "loss: 0.3704 - accuracy: 0.8453  \n",
    "[0.3703998923301697, 0.8453119397163391]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-battlefield",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-sydney",
   "metadata": {},
   "source": [
    "# 루브릭"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-hungarian",
   "metadata": {},
   "source": [
    "__1. SentencePiece를 이용하여 모델을 만들기까지의 과정이 정상적으로 진행되었는가?__  \n",
    "_(코퍼스 분석, 전처리, SentencePiece 적용, 토크나이저 구현 및 동작이 빠짐없이 진행되었는가?)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-least",
   "metadata": {},
   "source": [
    "- 데이터를 시각화한 후 분석(길이에 따른 분할 등) 및 전처리(중복 제거 등), SentencePiece 적용, sp_tokenize 구현 및 동작을 진행했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-hayes",
   "metadata": {},
   "source": [
    "__2. SentencePiece를 통해 만든 Tokenizer가 자연어처리 모델과 결합하여 동작하는가?__  \n",
    "_(SentencePiece 토크나이저가 적용된 Text Classifier 모델이 정상적으로 수렴하여 80% 이상의 test accuracy가 확인되었다.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-tower",
   "metadata": {},
   "source": [
    "- SentencePiece 모델의 model_type, vocab_size 등을 변경해 가면서 적용결과 모두 80% 이상의 test accuracy가 확인되었다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-function",
   "metadata": {},
   "source": [
    "__3. SentencePiece의 성능을 다각도로 비교분석하였는가?__  \n",
    "_(SentencePiece 토크나이저를 활용했을 때의 성능을 다른 토크나이저 혹은 SentencePiece의 다른 옵션의 경우와 비교하여 분석을 체계적으로 진행하였다.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-municipality",
   "metadata": {},
   "source": [
    "- Macab 진행시 SentencePiece와 동일한 vocab_size를 적용하려고 했으나 8k 적용시 오류가 발생해 체계적이지 못했다.\n",
    "- Epoch가 적어서인지 큰 차이가 보이지 않았다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-washer",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-prisoner",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-scale",
   "metadata": {},
   "source": [
    "- 아직도 데이터 전처리에서 많이 헤메고 있다.\n",
    "- 코드를 직접 짜는 부분이 많아지면서 아직도 기본이 많이 부족하다고 생각된다. 지금 모델이 아니라 코딩 공부를 해야하지 않나 싶다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336.903px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
