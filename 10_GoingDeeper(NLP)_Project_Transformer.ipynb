{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "placed-director",
   "metadata": {},
   "source": [
    "# Step 1. ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ë¡œì»¬ ìœ ì €ìš©)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-minneapolis",
   "metadata": {},
   "source": [
    "ì•„ë˜ ë§í¬ì—ì„œ korean-english-park.train.tar.gz ë¥¼ ë‹¤ìš´ë¡œë“œë°›ì•„ í•œì˜ ë³‘ë ¬ ë°ì´í„°ë¥¼ í™•ë³´í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-continent",
   "metadata": {},
   "source": [
    "- [jungyeul/korean-parallel-corpora](https://github.com/jungyeul/korean-parallel-corpora/tree/master/korean-english-news-v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-chess",
   "metadata": {},
   "source": [
    "_ğŸ’¡ì´ì „ [ Seq2seqìœ¼ë¡œ ë²ˆì—­ê¸° ë§Œë“¤ê¸° ] ì½”ìŠ¤ì—ì„œ ì‚¬ìš©í•œ ë°ì´í„°ì™€ ë™ì¼í•œ ë°ì´í„°ì…ë‹ˆë‹¤!_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-interstate",
   "metadata": {},
   "source": [
    "í„°ë¯¸ë„ì„ ì—´ì–´ì„œ í•˜ë‹¨ì˜ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-separation",
   "metadata": {},
   "source": [
    "```\n",
    "$ mkdir -p ~/aiffel/transformer/data\n",
    "$ cd ~/aiffel/transformer/data\n",
    "\n",
    "$ wget https://github.com/jungyeul/korean-parallel-corpora/raw/master/korean-english-news-v1/korean-english-park.train.tar.gz\n",
    "$ gzip -d korean-english-park.train.tar.gz\n",
    "$ tar -xvf korean-english-park.train.tar\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imposed-gibson",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T10:29:05.743765Z",
     "start_time": "2021-05-04T10:29:02.955287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from konlpy.tag import Mecab\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "import sentencepiece as spm\n",
    "import seaborn # Attention ì‹œê°í™”ë¥¼ ìœ„í•´ í•„ìš”!\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "associate-cambridge",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T10:29:06.462918Z",
     "start_time": "2021-05-04T10:29:05.753728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "import matplotlib.font_manager as fm\n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager._rebuild()\n",
    "\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-content",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-amateur",
   "metadata": {},
   "source": [
    "# Step 2. ë°ì´í„° ì •ì œ ë° í† í°í™”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-thesaurus",
   "metadata": {},
   "source": [
    "1) set ë°ì´í„°í˜•ì´ __ì¤‘ë³µì„ í—ˆìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì„ í™œìš©__í•´ ì¤‘ë³µëœ ë°ì´í„°ë¥¼ ì œê±°í•˜ë„ë¡ í•©ë‹ˆë‹¤. ë°ì´í„°ì˜ __ë³‘ë ¬ ìŒì´ ííŠ¸ëŸ¬ì§€ì§€ ì•Šê²Œ ì£¼ì˜__í•˜ì„¸ìš”! ì¤‘ë³µì„ ì œê±°í•œ ë°ì´í„°ë¥¼ cleaned_corpus ì— ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-pressing",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ë¡œë“œ ë° ì¤‘ë³µ ì œê±°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "painful-softball",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T10:29:20.709357Z",
     "start_time": "2021-05-04T10:29:20.513820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78968"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/transformer/data'\n",
    "kor_path = data_dir+\"/korean-english-park.train.ko\"\n",
    "eng_path = data_dir+\"/korean-english-park.train.en\"\n",
    "\n",
    "# ë°ì´í„° ì •ì œ ë° í† í°í™”\n",
    "def clean_corpus(kor_path, eng_path):\n",
    "    with open(kor_path, \"r\") as f: kor = f.read().splitlines()\n",
    "    with open(eng_path, \"r\") as f: eng = f.read().splitlines()\n",
    "    assert len(kor) == len(eng)\n",
    "\n",
    "    cleaned_corpus = list(set(zip(kor, eng)))\n",
    "\n",
    "    return cleaned_corpus\n",
    "\n",
    "cleaned_corpus = clean_corpus(kor_path, eng_path)\n",
    "len(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "racial-flight",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T10:29:44.742549Z",
     "start_time": "2021-05-04T10:29:44.732637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ê·¸ë“¤ì˜ í•´ì•…ì  ìœ ë¨¸ëŠ” ì²­ì¤‘ë“¤ì´ ëŠë‚„ ìˆ˜ ìˆëŠ” ë§ì€ ì–˜ê¸°ë¥¼ í•˜ë©° ê·¸ë“¤ì—ê²Œ ì¦ê±°ì›€ì„ ì£¼ê³  ìˆë‹¤.',\n",
       " 'Their biting humor is something to which many in their audience can relate.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_corpus[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-meter",
   "metadata": {},
   "source": [
    "2) ì •ì œ í•¨ìˆ˜ë¥¼ ì•„ë˜ ì¡°ê±´ì„ ë§Œì¡±í•˜ê²Œ ì •ì˜í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-graduation",
   "metadata": {},
   "source": [
    "## ì •ì œ í•¨ìˆ˜ ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-humor",
   "metadata": {},
   "source": [
    ">___ì¡°ê±´___\n",
    ">- _ëª¨ë“  ì…ë ¥ì„ ___ì†Œë¬¸ìë¡œ ë³€í™˜___í•©ë‹ˆë‹¤._\n",
    ">- ___ì•ŒíŒŒë²³, ë¬¸ì¥ë¶€í˜¸, í•œê¸€___ _ë§Œ ë‚¨ê¸°ê³  ëª¨ë‘ ì œê±°í•©ë‹ˆë‹¤._\n",
    ">- ___ë¬¸ì¥ë¶€í˜¸ ì–‘ì˜†ì— ê³µë°±___ _ì„ ì¶”ê°€í•©ë‹ˆë‹¤._\n",
    ">- _ë¬¸ì¥ ì•ë’¤ì˜ ___ë¶ˆí•„ìš”í•œ ê³µë°±ì„ ì œê±°___í•©ë‹ˆë‹¤._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "capital-scanning",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T10:34:31.301140Z",
     "start_time": "2021-05-04T10:34:31.289330Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    \n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    sentence = re.sub(r\"([?.!,Â¿Â¡])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Zã„±-í•˜-ã…£ê°€-í£0-9?.!,]+\", \" \", sentence) \n",
    "\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-message",
   "metadata": {},
   "source": [
    "3) í•œê¸€ ë§ë­‰ì¹˜ kor_corpus ì™€ ì˜ë¬¸ ë§ë­‰ì¹˜ eng_corpus ë¥¼ ê°ê° ë¶„ë¦¬í•œ í›„, __ì •ì œí•˜ì—¬ í† í°í™”ë¥¼ ì§„í–‰__í•©ë‹ˆë‹¤! __í† í°í™”ì—ëŠ” Sentencepieceë¥¼ í™œìš©__í•˜ì„¸ìš”. ì²¨ë¶€ëœ ê³µì‹ ì‚¬ì´íŠ¸ë¥¼ ì°¸ê³ í•´ ì•„ë˜ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” generate_tokenizer() í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ìµœì¢…ì ìœ¼ë¡œ ko_tokenizer ê³¼ en_tokenizer ë¥¼ ì–»ìœ¼ì„¸ìš”. en_tokenizerì—ëŠ” set_encode_extra_options(\"bos:eos\") í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•´ __íƒ€ê²Ÿ ì…ë ¥ì´ ë¬¸ì¥ì˜ ì‹œì‘ í† í°ê³¼ ë í† í°ì„ í¬í•¨í•  ìˆ˜ ìˆê²Œ__ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-evolution",
   "metadata": {},
   "source": [
    "> ___ì¡°ê±´___\n",
    ">- _ë‹¨ì–´ ì‚¬ì „ì„ ë§¤ê°œë³€ìˆ˜ë¡œ ë°›ì•„ ___ì›í•˜ëŠ” í¬ê¸°ì˜ ì‚¬ì „ì„ ì •ì˜___í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. (ê¸°ë³¸: 20,000)_\n",
    ">- _í•™ìŠµ í›„ ì €ì¥ëœ model íŒŒì¼ì„ SentencePieceProcessor() í´ë˜ìŠ¤ì— Load()í•œ í›„ ë°˜í™˜í•©ë‹ˆë‹¤._\n",
    ">- ___íŠ¹ìˆ˜ í† í°ì˜ ì¸ë±ìŠ¤___ _ë¥¼ ì•„ë˜ì™€ ë™ì¼í•˜ê²Œ ì§€ì •í•©ë‹ˆë‹¤._  \n",
    "_\\<PAD> : 0 / \\<BOS> : 1 /  \n",
    "\\<EOS> : 2 / \\<UNK> : 3_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-modem",
   "metadata": {},
   "source": [
    "- ì°¸ê³ : [google/sentencepiece](https://github.com/google/sentencepiece)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-allowance",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ë¶„í•  ì •ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "timely-customs",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T10:34:36.972670Z",
     "start_time": "2021-05-04T10:34:34.163420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78968\n",
      "78968\n"
     ]
    }
   ],
   "source": [
    "kor_corpus = []\n",
    "eng_corpus = []\n",
    "\n",
    "for sentence in cleaned_corpus:\n",
    "    ko_sentence = preprocess_sentence(sentence[0])\n",
    "    en_sentence = preprocess_sentence(sentence[1])\n",
    "    kor_corpus.append(ko_sentence)\n",
    "    eng_corpus.append(en_sentence)   \n",
    "    \n",
    "print(len(eng_corpus))\n",
    "print(len(kor_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "trained-vault",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T10:34:55.973556Z",
     "start_time": "2021-05-04T10:34:55.967994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korean : ê·¸ë“¤ì˜ í•´ì•…ì  ìœ ë¨¸ëŠ” ì²­ì¤‘ë“¤ì´ ëŠë‚„ ìˆ˜ ìˆëŠ” ë§ì€ ì–˜ê¸°ë¥¼ í•˜ë©° ê·¸ë“¤ì—ê²Œ ì¦ê±°ì›€ì„ ì£¼ê³  ìˆë‹¤ .\n",
      "English : their biting humor is something to which many in their audience can relate .\n"
     ]
    }
   ],
   "source": [
    "print(\"Korean :\", kor_corpus[100])   \n",
    "print(\"English :\", eng_corpus[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-ecology",
   "metadata": {},
   "source": [
    "## ë°ì´í„° í† í°í™” : Sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acute-annual",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T10:44:43.586715Z",
     "start_time": "2021-05-04T10:44:43.582134Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sentencepieceë¥¼ í™œìš©í•˜ì—¬ í•™ìŠµí•œ tokenizerë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "def generate_tokenizer(corpus,\n",
    "                       vocab_size,\n",
    "                       lang=\"ko\",\n",
    "                       pad_id=0,\n",
    "                       bos_id=1,\n",
    "                       eos_id=2,\n",
    "                       unk_id=3):\n",
    "\n",
    "    model_name = 'spm_GD10_'+lang\n",
    "\n",
    "    # ëª¨ë¸ ìƒì„± ê²½ë¡œ\n",
    "    temp_file = os.getenv(\n",
    "        'HOME')+'/aiffel/transformer/data/spm/GD10_'+lang+'.ko'\n",
    "\n",
    "    # í•¨ìˆ˜ íŒŒë¼ë¯¸í„° langì˜ ë‹¨ì–´ë¥¼ ì ìš©í•œ íŒŒì¼ ì½”í¼ìŠ¤ íŒŒì¼ ë§Œë“¬\n",
    "    with open(temp_file, 'w') as f:\n",
    "        for row in corpus:   # lang corpusë¥¼ í™œìš©í•©ë‹ˆë‹¤.\n",
    "            f.write(str(row) + '\\n')\n",
    "\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        '\\\n",
    "        --input={} \\\n",
    "        --model_prefix={} \\\n",
    "        --vocab_size={} \\\n",
    "        --pad_id={} \\\n",
    "        --bos_id={} \\\n",
    "        --eos_id={} \\\n",
    "        --unk_id={}'.format(temp_file, model_name, vocab_size, pad_id, bos_id, eos_id, unk_id)\n",
    "    )\n",
    "    # ìœ„ Trainì—ì„œ  --model_type = 'unigram'ì´ ë””í´íŠ¸ ì ìš©ë˜ì–´ ìˆìŠµë‹ˆë‹¤. --model_type = 'bpe' ë¡œ ì˜µì…˜ì„ ì£¼ì–´ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "    tokenizer = spm.SentencePieceProcessor()\n",
    "    tokenizer.Load(model_name+'.model')\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aerial-brazilian",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T10:44:58.160449Z",
     "start_time": "2021-05-04T10:44:44.418510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC_VOCAB_SIZE = TGT_VOCAB_SIZE = 20000\n",
    "\n",
    "ko_tokenizer = generate_tokenizer(kor_corpus, SRC_VOCAB_SIZE, \"ko\")\n",
    "en_tokenizer = generate_tokenizer(eng_corpus, TGT_VOCAB_SIZE, \"en\")\n",
    "en_tokenizer.set_encode_extra_options(\"bos:eos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-porter",
   "metadata": {},
   "source": [
    "4) í† í¬ë‚˜ì´ì €ë¥¼ í™œìš©í•´ __í† í°ì˜ ê¸¸ì´ê°€ 50 ì´í•˜__ì¸ ë°ì´í„°ë¥¼ ì„ ë³„í•˜ì—¬ src_corpus ì™€ tgt_corpus ë¥¼ ê°ê° êµ¬ì¶•í•˜ê³ , í…ì„œ enc_train ê³¼ dec_train ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”! (â—ëª¨ë“  ë°ì´í„°ë¥¼ ì‚¬ìš©í•  ê²½ìš° í•™ìŠµì— êµ‰ì¥íˆ ì˜¤ëœ ì‹œê°„ì´ ê±¸ë¦½ë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-highland",
   "metadata": {},
   "source": [
    "## í† í¬ë‚˜ì´ì§• & í…ì„œ ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "given-income",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T10:50:32.797034Z",
     "start_time": "2021-05-04T10:50:28.271916Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj24/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90fa14357259419b8c89823d7b5dc226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78968 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67942\n",
      "67942\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook    # Process ê³¼ì •ì„ ë³´ê¸° ìœ„í•´\n",
    "\n",
    "src_corpus = []\n",
    "tgt_corpus = []\n",
    "\n",
    "assert len(kor_corpus) == len(eng_corpus)\n",
    "\n",
    "# í† í°ì˜ ê¸¸ì´ê°€ 50 ì´í•˜ì¸ ë¬¸ì¥ë§Œ ë‚¨ê¹ë‹ˆë‹¤. \n",
    "for idx in tqdm_notebook(range(len(kor_corpus))):\n",
    "    token_ko = ko_tokenizer.encode_as_ids(kor_corpus[idx])\n",
    "    token_en = en_tokenizer.encode_as_ids(eng_corpus[idx])\n",
    "               \n",
    "    if len(token_ko) <= 50  and len(token_en) <= 50:\n",
    "        src_corpus.append(token_ko)\n",
    "        tgt_corpus.append(token_en)\n",
    "\n",
    "print(len(src_corpus))\n",
    "print(len(tgt_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "separate-march",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T10:50:37.870351Z",
     "start_time": "2021-05-04T10:50:37.864860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korean : [16, 7, 570, 337, 1550, 26, 1348, 3064, 10, 564, 21, 8823, 6, 1639, 5]\n",
      "English : [1, 30, 1354, 9, 265, 28, 11, 1199, 120, 18, 3964, 377, 47, 290, 9, 71, 11, 3821, 12, 5, 119, 14, 4138, 10, 5, 246, 6, 1277, 18, 3713, 34, 5, 3221, 7, 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Korean :\", src_corpus[100])   \n",
    "print(\"English :\", tgt_corpus[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "flush-temperature",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T10:50:43.830856Z",
     "start_time": "2021-05-04T10:50:43.214121Z"
    }
   },
   "outputs": [],
   "source": [
    "# íŒ¨ë”©ì²˜ë¦¬ë¥¼ ì™„ë£Œí•˜ì—¬ í•™ìŠµìš© ë°ì´í„°ë¥¼ ì™„ì„±í•©ë‹ˆë‹¤. \n",
    "enc_train = tf.keras.preprocessing.sequence.pad_sequences(src_corpus, padding='post')\n",
    "dec_train = tf.keras.preprocessing.sequence.pad_sequences(tgt_corpus, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "familiar-investing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T10:50:45.708705Z",
     "start_time": "2021-05-04T10:50:45.702106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67942, 50)\n",
      "(67942, 50)\n"
     ]
    }
   ],
   "source": [
    "print(enc_train.shape)\n",
    "print(dec_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-tulsa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-vitamin",
   "metadata": {},
   "source": [
    "# tep 3. ëª¨ë¸ ì„¤ê³„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-senate",
   "metadata": {},
   "source": [
    "ì˜¤ëŠ˜ ë°°ìš´ ë‚´ìš©ì„ í™œìš©í•´ì„œ Transformer ëª¨ë¸ì„ ì„¤ê³„í•´ë³´ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-chosen",
   "metadata": {},
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "direct-latitude",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T10:52:25.227797Z",
     "start_time": "2021-05-04T10:52:25.222765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, int(i) / d_model)\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "\n",
    "    return sinusoid_table\n",
    "\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-gibson",
   "metadata": {},
   "source": [
    "## Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "macro-lloyd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T10:53:43.727106Z",
     "start_time": "2021-05-04T10:53:43.716417Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        split_x = tf.reshape(x, (bsz, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (bsz, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "\n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "\n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "\n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "\n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-roller",
   "metadata": {},
   "source": [
    "## Position-wise Feed-Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "royal-matter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T10:54:22.290229Z",
     "start_time": "2021-05-04T10:54:22.285622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.w_2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.w_1(x)\n",
    "        out = self.w_2(out)\n",
    "            \n",
    "        return out\n",
    "\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-palestinian",
   "metadata": {},
   "source": [
    "## Encoder ë ˆì´ì–´ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "delayed-muscle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T10:55:21.021112Z",
     "start_time": "2021-05-04T10:55:21.013205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn\n",
    "\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-louisville",
   "metadata": {},
   "source": [
    "## Decoder ë ˆì´ì–´ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "consistent-width",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T10:55:47.443620Z",
     "start_time": "2021-05-04T10:55:47.434268Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Masked Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, causality_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out, dec_enc_attn = self.enc_dec_attn(out, enc_out, enc_out, padding_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-interpretation",
   "metadata": {},
   "source": [
    "## Encoder í´ë˜ìŠ¤ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "velvet-domestic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T12:25:19.763955Z",
     "start_time": "2021-05-04T12:25:19.758633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "    \n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns\n",
    "\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-limit",
   "metadata": {},
   "source": [
    "## Decoder í´ë˜ìŠ¤ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "disciplinary-calgary",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T12:25:20.711117Z",
     "start_time": "2021-05-04T12:25:20.706691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "                            \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns\n",
    "\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-pride",
   "metadata": {},
   "source": [
    "## Transformer í´ë˜ìŠ¤ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "opposite-catch",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T12:25:21.570699Z",
     "start_time": "2021-05-04T12:25:21.564118Z"
    }
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout=0.2,\n",
    "                    shared=True):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared = shared\n",
    "\n",
    "        if shared: self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.do(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "\n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
    "\n",
    "        logits = self.fc(dec_out)\n",
    "\n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-murray",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "psychological-defendant",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T12:25:22.434792Z",
     "start_time": "2021-05-04T12:25:22.429117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_causality_mask(src_len, tgt_len):\n",
    "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
    "    return tf.cast(mask, tf.float32)\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_mask = generate_padding_mask(tgt)\n",
    "\n",
    "    dec_enc_causality_mask = generate_causality_mask(tgt.shape[1], src.shape[1])\n",
    "    dec_enc_mask = tf.maximum(enc_mask, dec_enc_causality_mask)\n",
    "\n",
    "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
    "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask\n",
    "\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-destiny",
   "metadata": {},
   "source": [
    "## LearningRateSchedule í´ë˜ìŠ¤ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "systematic-frank",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T12:25:23.289501Z",
     "start_time": "2021-05-04T12:25:23.285934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-matrix",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-click",
   "metadata": {},
   "source": [
    "# Step 4. í›ˆë ¨í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-maker",
   "metadata": {},
   "source": [
    "ì•ì„œ í•„ìš”í•œ ê²ƒë“¤ì„ ëª¨ë‘ ì •ì˜í–ˆê¸° ë•Œë¬¸ì— ìš°ë¦¬ëŠ” í›ˆë ¨ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤! ì•„ë˜ ê³¼ì •ì„ ì°¨ê·¼ì°¨ê·¼ ë”°ë¼ê°€ë©° ëª¨ë¸ì„ í›ˆë ¨í•˜ê³ , __ì˜ˆë¬¸ì— ëŒ€í•œ ë©‹ì§„ ë²ˆì—­__ì„ ì œì¶œí•˜ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-repeat",
   "metadata": {},
   "source": [
    "## Transformer ì„ ì–¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-camel",
   "metadata": {},
   "source": [
    "1. __2 Layer__ë¥¼ ê°€ì§€ëŠ” Transformerë¥¼ ì„ ì–¸í•˜ì„¸ìš”.\n",
    "(í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ììœ ë¡­ê²Œ ì¡°ì ˆí•©ë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "brazilian-coast",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T12:25:27.154712Z",
     "start_time": "2021-05-04T12:25:27.045452Z"
    }
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    n_layers = 2,\n",
    "    d_model = 512,\n",
    "    n_heads = 8,\n",
    "    d_ff = 2048,\n",
    "    src_vocab_size=20000,\n",
    "    tgt_vocab_size=20000,\n",
    "    pos_len=50,\n",
    "    dropout = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-subject",
   "metadata": {},
   "source": [
    "## Optimizertion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-france",
   "metadata": {},
   "source": [
    "2. ë…¼ë¬¸ì—ì„œ ì‚¬ìš©í•œ ê²ƒê³¼ ë™ì¼í•œ __Learning Rate Scheduler__ë¥¼ ì„ ì–¸í•˜ê³ , ì´ë¥¼ í¬í•¨í•˜ëŠ” __Adam Optimizer__ë¥¼ ì„ ì–¸í•˜ì„¸ìš”. (Optimizerì˜ íŒŒë¼ë¯¸í„° ì—­ì‹œ ë…¼ë¬¸ê³¼ ë™ì¼í•˜ê²Œ ì„¤ì •í•©ë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "swiss-sheriff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T12:26:06.338917Z",
     "start_time": "2021-05-04T12:26:06.333022Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = LearningRateScheduler(512)\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-09, \n",
    "    name='Adam'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-spokesman",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-ivory",
   "metadata": {},
   "source": [
    "3. __Loss í•¨ìˆ˜ë¥¼ ì •ì˜__í•˜ì„¸ìš”.\n",
    "Sequence-to-sequence ëª¨ë¸ì—ì„œ ì‚¬ìš©í–ˆë˜ Lossì™€ ìœ ì‚¬í•˜ë˜, __Masking ë˜ì§€ ì•Šì€ ì…ë ¥ì˜ ê°œìˆ˜ë¡œ Scaling__í•˜ëŠ” ê³¼ì •ì„ ì¶”ê°€í•©ë‹ˆë‹¤. (íŠ¸ëœìŠ¤í¬ë¨¸ê°€ ëª¨ë“  ì…ë ¥ì— ëŒ€í•œ Lossë¥¼ í•œ ë²ˆì— êµ¬í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "earned-correspondence",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T12:29:58.761117Z",
     "start_time": "2021-05-04T12:29:58.757751Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    # Masking ë˜ì§€ ì•Šì€ ì…ë ¥ì˜ ê°œìˆ˜ë¡œ Scalingí•˜ëŠ” ê³¼ì •\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-capitol",
   "metadata": {},
   "source": [
    "## Train Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-absorption",
   "metadata": {},
   "source": [
    "4. __train_step í•¨ìˆ˜__ë¥¼ ì •ì˜í•˜ì„¸ìš”.\n",
    "__ì…ë ¥ ë°ì´í„°ì— ì•Œë§ì€ Maskë¥¼ ìƒì„±__í•˜ê³ , ì´ë¥¼ ëª¨ë¸ì— ì „ë‹¬í•˜ì—¬ ì—°ì‚°ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "immune-belfast",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T12:31:15.009574Z",
     "start_time": "2021-05-04T12:31:15.002875Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train Step í•¨ìˆ˜ ì •ì˜\n",
    "\n",
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    gold = tgt[:, 1:]\n",
    "        \n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
    "\n",
    "    # ê³„ì‚°ëœ lossì— tf.GradientTape()ë¥¼ ì ìš©í•´ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions[:, :-1])\n",
    "\n",
    "    # ìµœì¢…ì ìœ¼ë¡œ optimizer.apply_gradients()ê°€ ì‚¬ìš©ë©ë‹ˆë‹¤. \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-assignment",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-threshold",
   "metadata": {},
   "source": [
    "5. __í•™ìŠµì„ ì§„í–‰__í•©ë‹ˆë‹¤.\n",
    "__ë§¤ Epoch ë§ˆë‹¤ ì œì‹œëœ ì˜ˆë¬¸ì— ëŒ€í•œ ë²ˆì—­ì„ ìƒì„±__í•˜ê³ , ë©‹ì§„ ë²ˆì—­ì´ ìƒì„±ë˜ë©´ ê·¸ë•Œì˜ __í•˜ì´í¼íŒŒë¼ë¯¸í„°ì™€ ìƒì„±ëœ ë²ˆì—­ì„ ì œì¶œ__í•˜ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-supervisor",
   "metadata": {},
   "source": [
    "__ì˜ˆë¬¸__\n",
    "``` python\n",
    "1. ì˜¤ë°”ë§ˆëŠ” ëŒ€í†µë ¹ì´ë‹¤.\n",
    "2. ì‹œë¯¼ë“¤ì€ ë„ì‹œ ì†ì— ì‚°ë‹¤.\n",
    "3. ì»¤í”¼ëŠ” í•„ìš” ì—†ë‹¤.\n",
    "4. ì¼ê³± ëª…ì˜ ì‚¬ë§ìê°€ ë°œìƒí–ˆë‹¤.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-synthesis",
   "metadata": {},
   "source": [
    "__ê²°ê³¼(output)__\n",
    "``` python\n",
    "Translations\n",
    "> 1. obama is the president elect .\n",
    "> 2. they are in the city .\n",
    "> 3. they don t need to be a lot of drink .\n",
    "> 4. seven other people have been killed in the attacks .\n",
    "\n",
    "Hyperparameters\n",
    "> n_layers: 2\n",
    "> d_model: 512\n",
    "> n_heads: 8\n",
    "> d_ff: 2048\n",
    "> dropout: 0.3\n",
    "\n",
    "Training Parameters\n",
    "> Warmup Steps: 4000\n",
    "> Batch Size: 64\n",
    "> Epoch At: 5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-resource",
   "metadata": {},
   "source": [
    "ë²ˆì—­ ìƒì„±ì—ëŠ” ì•„ë˜ ì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "criminal-escape",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T12:32:13.082950Z",
     "start_time": "2021-05-04T12:32:13.072996Z"
    }
   },
   "outputs": [],
   "source": [
    "# Attention ì‹œê°í™” í•¨ìˆ˜\n",
    "\n",
    "def visualize_attention(src, tgt, enc_attns, dec_attns, dec_enc_attns):\n",
    "    def draw(data, ax, x=\"auto\", y=\"auto\"):\n",
    "        import seaborn\n",
    "        seaborn.heatmap(data, \n",
    "                        square=True,\n",
    "                        vmin=0.0, vmax=1.0, \n",
    "                        cbar=False, ax=ax,\n",
    "                        xticklabels=x,\n",
    "                        yticklabels=y)\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Encoder Layer\", layer + 1)\n",
    "        for h in range(4):\n",
    "            draw(enc_attns[layer][0, h, :len(src), :len(src)], axs[h], src, src)\n",
    "        plt.show()\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Decoder Self Layer\", layer+1)\n",
    "        for h in range(4):\n",
    "            draw(dec_attns[layer][0, h, :len(tgt), :len(tgt)], axs[h], tgt, tgt)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Decoder Src Layer\", layer+1)\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        for h in range(4):\n",
    "            draw(dec_enc_attns[layer][0, h, :len(tgt), :len(src)], axs[h], src, tgt)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "stopped-devices",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T12:32:17.904909Z",
     "start_time": "2021-05-04T12:32:17.898203Z"
    }
   },
   "outputs": [],
   "source": [
    "# ë²ˆì—­ ìƒì„± í•¨ìˆ˜\n",
    "\n",
    "def evaluate(sentence, model, src_tokenizer, tgt_tokenizer):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    pieces = src_tokenizer.encode_as_pieces(sentence)\n",
    "    tokens = src_tokenizer.encode_as_ids(sentence)\n",
    "\n",
    "    _input = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
    "                                                           maxlen=enc_train.shape[-1],\n",
    "                                                           padding='post')\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([tgt_tokenizer.bos_id()], 0)\n",
    "    for i in range(dec_train.shape[-1]):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "        generate_masks(_input, output)\n",
    "\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
    "        model(_input, \n",
    "              output,\n",
    "              enc_padding_mask,\n",
    "              combined_mask,\n",
    "              dec_padding_mask)\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if tgt_tokenizer.eos_id() == predicted_id:\n",
    "            result = tgt_tokenizer.decode_ids(ids)\n",
    "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = tgt_tokenizer.decode_ids(ids)\n",
    "\n",
    "    return pieces, result, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "palestinian-spending",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T12:32:45.644750Z",
     "start_time": "2021-05-04T12:32:45.639775Z"
    }
   },
   "outputs": [],
   "source": [
    "# ë²ˆì—­ ìƒì„± ë° Attention ì‹œê°í™” ê²°í•©\n",
    "\n",
    "def translate(sentence, model, src_tokenizer, tgt_tokenizer, plot_attention=False):\n",
    "    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "    evaluate(sentence, model, src_tokenizer, tgt_tokenizer)\n",
    "    \n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    if plot_attention:\n",
    "        visualize_attention(pieces, result.split(), enc_attns, dec_attns, dec_enc_attns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-jumping",
   "metadata": {},
   "source": [
    "translate() í•¨ìˆ˜ì˜ plot_attention ë³€ìˆ˜ë¥¼ True ë¡œ ì£¼ë©´ ë²ˆì—­ ê²°ê³¼ì— ëŒ€í•œ Attention Mapì„ ì‹œê°í™” í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ğŸ’¡ ì´ë²ˆ í”„ë¡œì íŠ¸ì—ì„œ ì œì‹œí•œ ì˜ˆë¬¸ì€ Seq2seqìœ¼ë¡œ ë²ˆì—­ê¸° ë§Œë“¤ê¸°ì˜ ì˜ˆë¬¸ê³¼ ë™ì¼í•©ë‹ˆë‹¤. Seq2seqê³¼ Transformerë¡œ ë§Œë“  ë‘ ë²ˆì—­ê¸°ì˜ ì„±ëŠ¥ì„ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì • ë“± ë‹¤ì–‘í•œ ì—°êµ¬í•´ë³´ì‹œë©´ í•™ìŠµì— ë„ì›€ì´ ë˜ì‹¤ ê±°ì˜ˆìš”!\n",
    "\n",
    "ë§ˆì§€ë§‰ìœ¼ë¡œ, í•™ìŠµì˜ ì „ ê³¼ì •ì„ êµ¬í˜„í•œ ì½”ë“œë¥¼ ì²¨ë¶€í•©ë‹ˆë‹¤. êµ¬í˜„ê³¼ì •ì— ì°¸ê³ í•´ ì£¼ì„¸ìš”. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-football",
   "metadata": {},
   "source": [
    "``` python\n",
    "# í•™ìŠµ\n",
    "\n",
    "from tqdm import tqdm_notebook \n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "\n",
    "examples = [\n",
    "            \"ì˜¤ë°”ë§ˆëŠ” ëŒ€í†µë ¹ì´ë‹¤.\",\n",
    "            \"ì‹œë¯¼ë“¤ì€ ë„ì‹œ ì†ì— ì‚°ë‹¤.\",\n",
    "            \"ì»¤í”¼ëŠ” í•„ìš” ì—†ë‹¤.\",\n",
    "            \"ì¼ê³± ëª…ì˜ ì‚¬ë§ìê°€ ë°œìƒí–ˆë‹¤.\"\n",
    "]\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "\n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm_notebook(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                    dec_train[idx:idx+BATCH_SIZE],\n",
    "                    transformer,\n",
    "                    optimizer)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "\n",
    "    for example in examples:\n",
    "        translate(example, transformer, ko_tokenizer, en_tokenizer)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ\n",
    "\n",
    "from tqdm import tqdm_notebook \n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "\n",
    "examples = [\n",
    "            \"ì˜¤ë°”ë§ˆëŠ” ëŒ€í†µë ¹ì´ë‹¤.\",\n",
    "            \"ì‹œë¯¼ë“¤ì€ ë„ì‹œ ì†ì— ì‚°ë‹¤.\",\n",
    "            \"ì»¤í”¼ëŠ” í•„ìš” ì—†ë‹¤.\",\n",
    "            \"ì¼ê³± ëª…ì˜ ì‚¬ë§ìê°€ ë°œìƒí–ˆë‹¤.\"\n",
    "]\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "\n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm_notebook(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                    dec_train[idx:idx+BATCH_SIZE],\n",
    "                    transformer,\n",
    "                    optimizer)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "\n",
    "    for example in examples:\n",
    "        translate(example, transformer, ko_tokenizer, en_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-pricing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-blind",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-mixture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-writing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-perspective",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-ownership",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-monte",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-offense",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-delay",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-decline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-estimate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-surrey",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-rebate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-robin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-capture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-snowboard",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-january",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-accounting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-scholarship",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-forwarding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-screw",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-columbia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-blackberry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-wireless",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-space",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-quarterly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-campbell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-partnership",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-adult",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-estate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-childhood",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-hawaii",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-landscape",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-individual",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-chair",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-giant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-constant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-boutique",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-comment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-pressure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-yeast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-research",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-kentucky",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-grove",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
